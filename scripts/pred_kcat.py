"""
AUTHOR: E Karvelis (karvels2@mit.edu)
PURPOSE:
Helper functions and classes for the dl_kcat repo
"""

# Import dependencies
import pandas as pd
import numpy as np
import pickle
import tempfile
import matplotlib.pyplot as plt
import seaborn as sns
import os
from glob import glob
import time
from scipy.stats import spearmanr, pearsonr
from sklearn.metrics import roc_auc_score as AUROC
from denseweight import DenseWeight
import itertools

# From PyTorch
import torch
from torch import nn, Tensor
from torch.utils.data import Dataset, DataLoader



"""
Helper functions
"""
def sem(a):
    # Returns standard error of the mean (SEM) of values in array a
    
    std = np.std(a, ddof=1)
    sem = std / ((a.shape[0])**0.5)
    return sem

def lookup_kcat(var, tmp_meta):
	# get kcat-related metadata for specific variant var
	var_path = np.where(np.array(tmp_meta.variant) == var)[0][0]
	kcat = tmp_meta.kcat[var_path]
	kcat_class = 1 if np.log10(kcat) > 21 else 0
	return kcat, kcat_class

def calc_lambda(data, order=None, n=100):
	# Calculates lambda for a randomly sampled subset of pathways
	# from a PathDataset object.
    # INPUT
    # data  -- PathDataset object.
    # order -- Order of pathways for which to calculate lambda
    #          0.8 is 'reactive' and -0.4 is 'non-reactive'.
    #          Default, None, selects from any and all pathways.
    # n     --  Number of pathways to randomly sample.
    if order is None:
        sele_paths = np.random.choice(np.arange(data.data.shape[0]), size=n, replace=False)
    else:
        elligible = np.where(np.array(data.meta.order) == order)
        sele_paths = np.random.choice(np.arange(data.data.shape[0])[elligible], size=n, replace=False)  
    
    making   = data.data[sele_paths,:,np.where(data.meta.ft_names == 'Dist AC6/C5,AC6/C7')[0][0]]
    breaking = data.data[sele_paths,:,np.where(data.meta.ft_names == 'Dist AC6/C5,AC6/C4')[0][0]]
    lam = breaking - making
    return lam

def plot_lam(data, n=100):
	# Plots lambda for a randomly sampled subset of pathways
	# from a PathDataset object.
    # INPUT
    # data  -- PathDataset object.
    # n     --  Number of pathways to randomly sample.

    lam_nr = calc_lambda(data, order=-0.4, n=n)
    lam_r  = calc_lambda(data, order=0.8, n=n)
    x = np.vstack([data.meta.timesteps]*lam_nr.shape[0])

    fig, axes = plt.subplots(1,2, figsize=(9,3))
    colors = ['k','r']
    labels = ['Non-reactive', 'Reactive']
    for i,lam in enumerate([lam_nr, lam_r]):
        axes.flatten()[1].plot(x.T, lam.T, alpha=0.3, c=colors[i])
        axes.flatten()[0].plot(np.mean(x.T, axis=1), np.mean(lam.T, axis=1), 
                               label=labels[i], alpha=0.9, c=colors[i])
        axes.flatten()[0].fill_between(np.mean(x.T, axis=1),
                                    np.mean(lam.T, axis=1)-np.std(lam.T, ddof=1, axis=1),
                                    np.mean(lam.T, axis=1)+np.std(lam.T, ddof=1, axis=1), 
                                    alpha=0.3, color=colors[i])
    
    axes.flatten()[0].set_ylabel(r"$\lambda$ ($\AA$)")
    axes.flatten()[0].set_title(r"Average $\pm$ standard deviation")
    axes.flatten()[1].set_title(r"Individual pathways")
    axes.flatten()[0].legend()
    fig.text(0.47, 0.001, 'Timestep (fs)')
    fig.tight_layout()
    return fig



"""
Custom classes for data piping and handling with PyTorch
"""
class PathDataset():
	# Stores the memory-mapped numpy array and corresponding
	# Recurrent_data object with associated metadata

	def __init__(self, data_file, meta_file=None, path_set_size=10, selected_variants=['*'],
				 features=['*'], task='kcat regression', mixed_variants=False, time_range=['*']):
		# INPUT:
		# All input are as described at the top of this file
		# data_file --        Name of the data file, which stores a memory-mapped numpy array of
		#                     the form saved by prep_data.py. This array has form 
		#                     [pathways, timesteps, features]. (str)
		# meta_file --        Name of the metadata file, which stores the metadata describing 
		#                     each pathway entry (along axis 0) of the data_file. The meta_file
		#                     stores a saved, pickled python object generated by prep_data.py when 
		#                     saving the corresponding data_file (meta_file will have the same name
		#                     as its data_file, but the suffix of the data_file is replaced with 
		#                     '.metadata'). This object is an instance of Recurrent_data as defined in
		#                     scripts/prep_data.py. It contains information associated with each 
		#                     pathway along axis 0 of the data_file array: the variant, k_cat, 
		#                     error in k_cat, pathway type (i.e., order), ensemble seed number, 
		#                     ensemble statistical replicate number, time steps (along axis 1). (str)
		# path_set_size --    The number of pathways to include per 'observation' of an enzyme
		#                     variant. That is, the model will predict k_cat from a set of 
		#                     path_set_size number of pathways from a given variant. The model
		#                     architecture will be designed so that it can make this prediction
		#                     for any variable number of pathways, but for training purposes, 
		#                     we select the number of pathways so that the training data can 
		#                     be appropriately packed into 'observations,' where each observation 
		#                     is a small set of pathways. Defaults to 10. int
		# selected_variants -- The variants whose data to use. This setting allows one to 
		#                     specify that only a subset of the variants are to be used. 
		#                     For example, if you wish to train and test on only WT, you
		#                     could pass selected_variants = ['WT']. Or if you wanted 
		#                     to train on only a few of the fastest mutants, you could 
		#                     pass ['GLn140Met-Thr520Asp', 'Leu501His','Thr520Asp']. 
		#                     Defaults to ['*'], in which case all variants available in 
		#                     the dataset are used. (list of strings, or the character '*')
		# features --         Names of the structural features to use for model training and 
		#                     evaluation. Default, corresponding to features = ['*'], is to 
		#                     use all available features (70 different interatomic distances, 
		#                     angles, and dihedral angles), but by specifying this variable, 
		#                     you can select a subset of features. You must specify features 
		#                     that are actually in the dataset by name. For example, 
		#                     features = ['Dist AC6/C5,AC6/C4', 'Dist AC6/C5,AC6/C7']
		#					  The order doesn't matter; it won't affect the data at all.
		#                     You can access a list of feature names by loading meta_file 
		#                     (see above) to some object, say meta, and then printing 
		#                     meta.ft_names.
		#					  Default, ['*']. (list of strings)
		# task 			 --   The type of learning task for which to train and evaluate the 
		#                     model. Must be one of:
		#                     'kcat regression' -- regression task to predict log10(kcat)
		#                     'NR/R binary classification' -- classify paths as either non-reactive or
		#                                                     reactive
		#                     'S/F binary classification' -- classify paths as belonging to a mutant
		#                                                 that was either slower or faster than WT
		#                     Default, 'kcat regression'. (str)
		# time_range --       Range of time points to include from data. If set to ['*'], then
		# 					  all the time points available in the dataset will be used. 
		#					  Otherwise, time specifies the minimum and maximum time points 
		# 					  defining the time window (inclusive). E.g., time = [-160,-130]
		#					  specifies a 31 step-long time window from -160 fs to -130 fs.
		#					  Default, ['*']. (list of str or int)
		self.data_file = data_file
		self.path_set_size = path_set_size
		self.selected_variants = selected_variants
		self.task = task
		self.mixed_variants = mixed_variants

		# set self.uniform parameter:
		# whether each observation of a variant in the self.obs
		# object is comprised of pathways of the same type. If
		# True, then each observation will contain pathways that
		# are all either reactive (R) or non-reactive (NR), but
		# never both. When False (default), observations can 
		# contain a mixture of all types of pathways. (bool)
		if self.task == 'kcat regression':
			self.uniform = False
		elif self.task == 'NR/R binary classification':
			self.uniform = True
		elif self.task == 'S/F binary classification':
			self.uniform = False

		if meta_file != None:
			self.meta_file = meta_file
		else:
			suffix = data_file.split('num')[-1].split('.')[-1]
			self.meta_file = data_file.replace(suffix, 'metadata')


		self.data = np.memmap(self.data_file, dtype='float32', mode='r', shape=self.get_data_shape(self.data_file))
		self.meta = pickle.load(open(self.meta_file, 'rb'))
		self.obs = None

		# select the desired time range
		if time_range[0] != '*':
			sele_tmin, sele_tmax = int(time_range[0]), int(time_range[1]) # user-specified bounds on time window
			tmin_idx = np.where(self.meta.timesteps == sele_tmin)[0][0]
			tmax_idx = np.where(self.meta.timesteps == sele_tmax)[0][0]
			self.data = self.data[:, tmin_idx:(tmax_idx+1), :]
			self.meta.timesteps = np.arange(sele_tmin, (sele_tmax+1))

		if self.selected_variants[0] == '*':
			# then use all the variants
			self.selected_variants = np.unique(self.meta.variant)

		if features[0] != '*':
			slctd_ft_idx = np.where(np.isin(self.meta.ft_names, features))[0]

			if slctd_ft_idx.shape[0] < len(features):
				raise ValueError('Fewer features were selected than requested; double-check the entries' +\
								 ' in features because it is likely one is mispelled or nonexistent.')

			self.data = self.data[:,:,slctd_ft_idx]
			self.meta.ft_names = self.meta.ft_names[slctd_ft_idx]

	def info(self):
		print ("self.data_file -- name of the file the PathDataset is sourcing a memory-mapped numpy array from")
		print ("self.meta_file -- name of the file the PathDataset is sourcing the meta data from (Recurrent_data object)")
		print ("self.data -- the loaded memory-mapped numpy array")
		print ("self.meta -- the loaded Recurrent_data object with metadata")
		print ("self.obs -- instance of Observations object. Stores indexes for each 'observation' of a mutant")

	@staticmethod
	def get_data_shape(data_file):
		suffix = data_file.split('num')[-1].split('.')[-1]
		shape = np.array(suffix.split('memnpy')[0].split('-'), dtype=int)
		shape = tuple(shape)
		return shape

	def make_observations(self):
		# Populates self.obs with an instance of the Observations class
		# 
		# This creates small groups of pathways, where each pathway
		# in a given group is from the same enzyme variant. Such
		# a group of pathways is called an 'observation' of a variant.
		# 
		# Observations are organized in an instance of the Observations 
		# class stored in self.obs.
		# Each observation has one element in the array self.obs.obs,
		# and that element is an array listing the indexes (along axis 0)
		# of self.data for the pathways belonging to that observation.
		# Also included as part of the self.obs instance are the 
		# self.obs.variant, self.obs.kcat, and self.obs.kcat_sem attibutes, 
		# which are arrays that respectively list the variant, kcat, and 
		# kcat SEM associated with each observation in self.obs.obs. Note 
		# that these attributes of self.obs are redundant in that self 
		# already has attributes containing this kind of information. The 
		# copying of variant and kcat-related metrics to self.obs is for 
		# convenience. If this causes issues later on (memory, general 
		# performance), consider doing away with the redundancy.

		if not self.mixed_variants:
			self.obs = self.Observations(self)
		else:
			self.obs = self.MixedObservations(self)

	class Observations():
		# Populates an array called self.obs, listing the indexes (along axis 0)
		# of PathDataset.data for the pathways belonging to each observation.
		# Also creates self.variant, self.kcat, and self.kcat_sem attibutes, 
		# which are arrays that respectively list the variant, kcat, and 
		# kcat SEM associated with each observation (each row) in self.obs.
		def __init__(self, PathDataset):
			self.obs = []
			self.variant = []
			self.kcat = []
			self.kcat_sem = []
			self.order = []

			for var in np.unique(PathDataset.meta.variant):

				if var in PathDataset.selected_variants:
					
					var_paths = np.where(np.array(PathDataset.meta.variant) == var)[0]

					# get kcat-related metadata
					kcat = PathDataset.meta.kcat[var_paths[0]]
					kcat_sem = PathDataset.meta.kcat_sem[var_paths[0]]

					# group variant's paths into a set of 'observations'
					if not PathDataset.uniform:
						# then each observation may contain a mix of both R and NR pathways
						n_obs = int(np.floor(var_paths.shape[0] / PathDataset.path_set_size))
						var_obs = np.random.choice(var_paths, size=(n_obs,PathDataset.path_set_size), replace=False)
					else:
						# then each observation may only contain either R or NR pathways, not both
						var_paths_nr = var_paths[np.where(np.array(PathDataset.meta.order)[var_paths] != 0.8)]
						n_obs_nr = int(np.floor(var_paths_nr.shape[0] / PathDataset.path_set_size))
						var_obs_nr = np.random.choice(var_paths_nr, size=(n_obs_nr,PathDataset.path_set_size), replace=False)

						var_paths_r = var_paths[np.where(np.array(PathDataset.meta.order)[var_paths] == 0.8)]
						n_obs_r = int(np.floor(var_paths_r.shape[0] / PathDataset.path_set_size))
						var_obs_r = np.random.choice(var_paths_r, size=(n_obs_r,PathDataset.path_set_size), replace=False)

						var_obs = np.vstack((var_obs_nr,var_obs_r))
					
					# append observations to list
					self.obs.append(var_obs)

					# add metadata
					self.variant     += [var]     *var_obs.shape[0]
					self.kcat        += [kcat]    *var_obs.shape[0]
					self.kcat_sem    += [kcat_sem]*var_obs.shape[0]
					self.order.append(np.array(PathDataset.meta.order)[var_obs])

			# convert all data to single numpy arrays
			self.variant = np.array(self.variant)
			self.kcat = np.array(self.kcat)
			self.kcat_sem = np.array(self.kcat_sem)
			self.obs = np.vstack(self.obs)
			self.order = np.vstack(self.order)

	class MixedObservations():
		# Populates an array called self.obs, listing the indexes (along axis 0)
		# of PathDataset.data for the pathways belonging to each observation.
		# Also creates self.variant, self.kcat, and self.kcat_sem attibutes, 
		# which are arrays that respectively list the variant(s), kcat, and 
		# kcat SEM associated with each observation (each row) in self.obs.
		# Because this is the MixedObservations class, the observations will 
		# be comprised of pathways that are sampled from a mixed set of 
		# different enzyme variants. The reported kcat will therefore be 
		# the arithmetic average of the different variants' kcat values, and 
		# the SEM will be the corresponding SEM. 
		
		def read_kcat(self, var):
			# get kcat-related metadata for specific variant var
			var_paths = np.where(np.array(self.pathdataset.meta.variant) == var)[0]
			kcat = self.pathdataset.meta.kcat[var_paths[0]]
			kcat_class = 1 if np.log10(kcat) > -16.02 else 0
			return kcat, kcat_class
		
		def generate_combos(self, variants):
			# create all combinations of variants from variants ranging from 
			# choose 1 up to choose self.n_pseudo_variants (which is the 
			# maximum number of variants to combine into a single 'pseudo variant')
			for i in range(self.n_pseudo_variants):
				self.pseudo_vars += list(itertools.combinations(variants, (i+1)))	

		def generate_pseudo_variants(self):
			variants = [v for v in np.unique(self.pathdataset.meta.variant) if v in self.pathdataset.selected_variants]
			fast_variants = [v for v in variants if self.read_kcat(v)[1] == 1]
			slow_variants = [v for v in variants if self.read_kcat(v)[1] == 0]

			if self.pathdataset.task == 'S/F binary classification':
				# then only create pseudo variants that are combinations of mutants from the same class
				self.generate_combos(slow_variants)
				self.generate_combos(fast_variants)
			else:
				self.generate_combos(variants)


		def __init__(self, pathdataset, n_pseudo_variants=2):
			# n_pseudo_variants is the number of individual mutants that may be selected
			# to be grouped together. For example, when n_pseudo_variants = 3, all 
			# real variants will be included, and all # of real variants choose 2, and 
			# all # of real variants choose 3
			self.obs = []
			self.variant = []
			self.kcat = []
			self.kcat_sem = []
			self.order = []
			self.pathdataset = pathdataset
			self.n_pseudo_variants = n_pseudo_variants
			self.pseudo_vars = []

			self.generate_pseudo_variants()

			print ('\n\n\nRUNNING MixedObservations\n\n\n')

			# set n_obs to fixed value equal to the number of times each single mutant is represented
			# pseudo_var_correction = 10 * np.array(self.pathdataset.selected_variants).shape[0] / len(self.pseudo_vars) # ratio of variants to pseudo_variants
			pseudo_var_correction = np.array(self.pathdataset.selected_variants).shape[0] / len(self.pseudo_vars)
			var_paths = np.where(np.array(self.pathdataset.meta.variant) == self.pathdataset.meta.variant[0])[0]
			n_obs = int(np.floor(var_paths.shape[0] / self.pathdataset.path_set_size) * pseudo_var_correction)

			if self.pathdataset.uniform:
				var_paths_nr = var_paths[np.where(np.array(self.pathdataset.meta.order)[var_paths] != 0.8)]
				n_obs_nr = int(np.floor(var_paths_nr.shape[0] / self.pathdataset.path_set_size) * pseudo_var_correction)
				
				var_paths_r = var_paths[np.where(np.array(self.pathdataset.meta.order)[var_paths] == 0.8)]
				n_obs_r = int(np.floor(var_paths_r.shape[0] / self.pathdataset.path_set_size) * pseudo_var_correction)


			for var in self.pseudo_vars:

				var_paths = np.where(np.isin(np.array(self.pathdataset.meta.variant), var))[0]

				# group pseudo variant's paths into a set of 'observations', where each observation
				# can be comprised of a mix of pathways from each of the variants within the pseudo variant
				if not self.pathdataset.uniform:
					# then each observation may contain a mix of both R and NR pathways
					var_obs = np.random.choice(var_paths, size=(n_obs,self.pathdataset.path_set_size), replace=False)
				else:
					# then each observation may only contain either R or NR pathways, not both
					var_paths_nr = var_paths[np.where(np.array(self.pathdataset.meta.order)[var_paths] != 0.8)]
					var_obs_nr = np.random.choice(var_paths_nr, size=(n_obs_nr,self.pathdataset.path_set_size), replace=False)

					var_paths_r = var_paths[np.where(np.array(self.pathdataset.meta.order)[var_paths] == 0.8)]
					var_obs_r = np.random.choice(var_paths_r, size=(n_obs_r,self.pathdataset.path_set_size), replace=False)

					var_obs = np.vstack((var_obs_nr,var_obs_r))

				# get kcat-related metadata and report kcat for each observation as the
				# average over the kcats of the variants in it
				kcat = np.array(self.pathdataset.meta.kcat)[var_obs]
				kcat_sem = np.std(kcat, axis=1, ddof=1) / (kcat.shape[1]**0.5)
				kcat = np.mean(kcat, axis=1)

				# add oberservations and metadata to lists
				self.obs.append(var_obs)
				self.variant.append(np.array(self.pathdataset.meta.variant)[var_obs])
				self.kcat        += list(kcat)
				self.kcat_sem    += list(kcat_sem)
				self.order.append(np.array(self.pathdataset.meta.order)[var_obs])

			# convert all data to single numpy arrays
			self.variant = np.vstack(self.variant)
			self.kcat = np.array(self.kcat)
			self.kcat_sem = np.array(self.kcat_sem)
			self.obs = np.vstack(self.obs)
			self.order = np.vstack(self.order)


class PathTorchDataset(Dataset):
	# Defines a customized Dataset class for use with 
	# PyTorch based on the standard PyTorch Dataset class
	

	def __init__(self, pathdataset, elligible_idxs=None, transform=None, control_model=False):
		# pathdataset -- an instance of the PathDataset object, with the 
		#                .obs attribute populated (PathDataset)
		# elligible_idxs -- the indexes along the attributes of
		#                   pathdataset.obs that are elligible for 
		#                   selection when loading data. This variable
		#                   is meant to pass the indexes of training or 
		#                   testing data. Default, None, in which case
		#                   all indexes are considered elligible. 
		#    				(numpy array, None).
		# transform -- transform to apply to samples (function, optional)
		# control_model -- if True, then the targets (labels), kcat, 
		# 				   will be randomly shuffled. (bool)

		self.pathdataset = pathdataset
		self.transform = transform
		self.control_model = control_model
		if elligible_idxs is None:
			self.elligible_idxs = np.arange(self.pathdataset.obs.obs.shape[0])
		else:
			self.elligible_idxs = elligible_idxs
		
		if self.control_model:
			self.elligible_idxs_shuffled = self.elligible_idxs.copy()
			np.random.shuffle(self.elligible_idxs_shuffled)

	def __len__(self):
		return (self.elligible_idxs.shape[0])

	def __getitem__(self, idx):

		# Convert idx to the index along self.path.dataset.obs
		# entries that is elligible for selection
		selected_idx = self.elligible_idxs[idx]

		# Collect paths' data
		path_idxs = self.pathdataset.obs.obs[selected_idx]
		paths = self.pathdataset.data[path_idxs,:,:]

		if self.control_model:
			# Update selected index to sample scrambled (random) target labels
			selected_idx = self.elligible_idxs_shuffled[idx]

		# Collect kcat value
		kcat = self.pathdataset.obs.kcat[selected_idx]
		log_kcat = np.float32(np.log10(kcat))
		kcat_sem = np.float32(self.pathdataset.obs.kcat_sem[selected_idx])

		# report whether value kcat is fast or slow, wrt WT
		kcat_class = 1 if log_kcat > -16.02 else 0
		kcat_class = np.float32(kcat_class)

		# Collect paths' order information
		order = self.pathdataset.obs.order[selected_idx]
		# we'll report order as the average across all the paths'
		# orders in the observation. If pathdataset.uniform, then
		# the average is exactly the order of all the paths in the
		# observation. Otherwise when pathdataset.uniform is False, 
		# the average will range from the lowest NR order to the 
		# R order depending on how many paths in the observation 
		# were R vs. NR
		order = np.mean(order)
		# encode the order parameter, if needed
		if self.pathdataset.task == 'NR/R binary classification': 
			order = 1 if order==0.8 else 0
		order = np.float32(order)

		sample = {'paths': paths,
				  'kcat': log_kcat,
				  'kcat sem': kcat_sem,
				  'order': order,
				  'kcat_class': kcat_class}

		if self.transform:
			sample = self.transform(sample)
		else:
			try:
				for i in sample:
					sample[i] = torch.from_numpy(sample[i]).to(device)
			except:
				# executes when PathTorchDataset is imported and executed by external programs
				for i in sample:
					sample[i] = torch.from_numpy(np.array(sample[i])).to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))

		return sample

class NormalScaler():
	# Similar to sklearn's StandardScaler() in that it scales
	# features to have mean=0 and variance=1 by applying 
	# z = (x-u)/s where z is the udpated feature value, x 
	# the original value, u the mean, and s the standard deviation.
	#
	# Given 3D data of form [pathways, timesteps, features], each 
	# feature's u and s are calculated across all timesteps across
	# all paths. So, there are data.shape[2] number of s and u 
	# in total
	# 
	# call .fit() to fit on training data, then
	# call .transform() to scale both training
	# and testing data as needed
	# 
	# Example:
	# scaler = NormalScaler()
	# scaler.fit(data.data)
	# x = data.data[0:3,:,:]
	# x = scaler.transform(x)

	def __init__(self):
		self.avg = None
		self.std = None

	def fit(self, x):
		self.avg = np.mean(x, axis=(0,1))
		self.std = np.std(x, axis=(0,1))

	def transform(self, x):
		if not isinstance(self.avg, np.ndarray):
			raise ValueError('NormalScaler instance must first be fit to data before transforming data')

		x = (x - self.avg) / self.std

		return x

class MinMaxScaler():
	# Similar to sklearn's MinMaxScaler() in that it scales
	# features to have range from 0 to 1 by applying 
	# x_scaled = (x - min(x))/(max(x) - min(x)) where x_scaled
	# is the udpated feature value, x  the original value
	#
	# Given 3D data of form [pathways, timesteps, features], each 
	# feature's min and max are taken across all timesteps across
	# all paths. So, there are data.shape[2] number of min and max 
	# in total
	# 
	# call .fit() to fit on training data, then
	# call .transform() to scale both training
	# and testing data as needed

	def __init__(self):
		self.min = None
		self.max = None

	def fit(self, x):
		self.min = np.min(np.min(x, axis=1), axis=0)
		self.max = np.max(np.max(x, axis=1), axis=0)

	def transform(self, x):
		if not isinstance(self.min, np.ndarray):
			raise ValueError('MinMaxScaler instance must first be fit to data before transforming data')

		x = (x - self.min) / (self.max - self.min)

		return x 

class DataScaler():
	# A class that can be passed as the transform argument when 
	# making an instance of PathTorchDataset, enabling the 
	# scaling, or normalization, of data as it is called by 
	# the PyTorch Dataloader.
	# INPUT:
	# scaler -- a MinMaxScaler or NormalScaler instance that has
	#           been fit to some data, which you want to apply
	# OUTPUT -- when __call__(sample) executes, this will apply
	#           the .transform() function of scaler to the data
	#           in sample['paths'], i.e. the pathway data

	def __init__(self, scaler, stoch_labels=False):
		self.scaler = scaler
		self.stoch_labels = stoch_labels

	@staticmethod
	def sample_kcat(mean, sem):
		# Samples a value from a normal distribution with mean = mean
		# and standard deviation = sem. Given that kcat must be > 0,
		# in the event that the sampled kcat < 0 (occurs 3-6% of time), 
		# new values are drawn until the sampled kcat is > 0
		kcat = -1
		while kcat <= 0:
			kcat = np.random.normal(loc=mean, scale=sem, size=1)[0]
		kcat = np.float32(np.log10(kcat))
		return kcat 
	
	@staticmethod
	def sample_lognormal_kcat(mean, sem):
		# Samples a value from a normal distribution with mean = mean
		# and standard deviation = sem. Use this to sample a log(kcat)
		# value, which can be negative
		kcat = np.random.normal(loc=mean, scale=sem, size=1)[0]
		kcat = np.float32(kcat)
		return kcat 

	def __call__(self, sample):

		paths = self.scaler.transform(sample['paths'])

		if self.stoch_labels:
			# sample kcat value from normal dist with mean = average 
			# kcat and std = SEM of kcat. Note: sample['kcat'] is in 
			# log units, so we take to the power of 10
			if self.stoch_labels == 'lognormal':
				kcat = self.sample_lognormal_kcat(sample['kcat'], 0.5) # hardcoded SEM = 0.5 to reflect average error in log(kcat) from table
			else:
				kcat = self.sample_kcat(10**sample['kcat'], sample['kcat sem'])
		else:
			kcat = sample['kcat']
		
		try:
			t_sample = {'paths': torch.from_numpy(paths).to(device),
						'kcat': torch.from_numpy(np.array(kcat)).to(device),
						'order': torch.from_numpy(np.array(sample['order'])).to(device),
						'kcat_class': torch.from_numpy(np.array(sample['kcat_class'])).to(device)}
		except:
			# executes when PathTorchDataset is imported and executed by external programs
			t_sample = {'paths': torch.from_numpy(paths).to(torch.device('cuda' if torch.cuda.is_available() else 'cpu')),
						'kcat': torch.from_numpy(np.array(kcat)).to(torch.device('cuda' if torch.cuda.is_available() else 'cpu')),
						'order': torch.from_numpy(np.array(sample['order'])).to(torch.device('cuda' if torch.cuda.is_available() else 'cpu')),
						'kcat_class': torch.from_numpy(np.array(sample['kcat_class'])).to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))}
			
		return t_sample



"""
Custom PyTorch classes of specific machine learning models
"""
class TransformerModel(nn.Module):
	# Encodes sets of multivariate time series with a transformer, 
	# pools the encodings, then uses the pooled encoding to predict
	# log(kcat) with an MLP prediction head

	def __init__(self, 
				 input_size: int,
				 input_length: int,
				 d_input_enc: int=128,
				 d_model: int=256,
				 max_input_length: int=500,
				 dropout_pos_encoder: float=0.1,
				 n_head: int=4,
				 d_tran_ffn: int=1024,
				 dropout_tran_encoder: float=0.2,
				 n_tran_layers: int=2,
				 d_mlp_head: int=128,
				 dropout_mlp_head: float=0.2,
				 task: str='kcat regression'):
		# INPUT:
		# input_size -- number of features in input. For example, 1 if univariate or 
		# 			    or 70 if using 70 structural features. int
		# input_length -- the length of each time series in time points. int
		# d_input_enc -- hidden layer size for the (middle layer of the) 2 layer input encoder
		# d_model -- the dimensions of the transformer encoder layers in the 
		#            transformer encoder. All sublayers in the model will produce
		#            outputs with this dimension. int
		# max_input_length -- the max length of the input sequence that is being fed to 
		#                 	  the model. This must be at least as large as the number of 
		#                 	  time points (i.e., input_length >= input_data.shape[-2]).
		#                     It is only used in defining the positional encoding.
		#                 	  Default, 500. int
		# dropout_pos_encoder -- dropout for the positional encoding step. Default, 0.1.
		#                        float
		# n_head -- the number of attention heads (parallel attention layers) in 
		#           each transformer encoder layer. Default, 8. int.
		# d_tran_ffn -- number of neurons in the linear feedforward layer of the transformer
		#               encoder layers. Default, 2048. int
		# dropout_tran_ecoder -- dropout for the transformer encoder layers. Default, 0.2.
		#                        float
		# n_tran_layers -- Number of stacked transformer encoder layers in the transformer
		#                  encoder. Default, 4. int
		# d_mlp_head -- hidden layer size for the (middle layer) of the two layer MLP
		#               regression head
		# dropout_mlp_head -- dropout rate applied in between the two layers in the 
		#                     MLP regression head
		# task -- the type of learning task
		# 
		#

		super().__init__()

		self.input_size = input_size
		self.input_length = input_length
		self.d_model = d_model
		self.model_type = 'PredictiveTransformerEncoder'
		self.task = task

		# Linear layer for encoding raw input
		self.input_encoder = nn.Sequential(nn.Linear(in_features=input_size, out_features=d_input_enc),
										   nn.ReLU(), #nn.Dropout(0.1) ???
							 			   nn.Linear(in_features=d_input_enc, out_features=d_model))

		# Positional encoder
		self.pos_encoder = PositionalEncoding(d_model, dropout_pos_encoder, input_length)

		# Transformer encoder
		encoder_layers = nn.TransformerEncoderLayer(d_model, n_head, 
												   dim_feedforward=d_tran_ffn,
												   dropout=dropout_tran_encoder,
												   batch_first=True)
		self.transformer_encoder = nn.TransformerEncoder(encoder_layers, n_tran_layers)

		# Prediction head (MLP layer)
		self.mlp_head = nn.Sequential(nn.Linear(in_features=d_model, out_features=d_mlp_head),
									  nn.ReLU(),
									  nn.Dropout(dropout_mlp_head),
									  nn.Linear(in_features=d_mlp_head, out_features=1))

		self.sigmoid = nn.Sigmoid() # used when self.task == 'NR/R binary classification'


	def forward(self, src: Tensor, src_mask: Tensor=None) -> Tensor:
		# INPUT
		# src -- the input data of shape [n_paths, timesteps, features] where
		#        n_paths is the number of pathways per observation (usually path_set_size),
		#        timesteps is the number of time steps in the series, and 
		#        features is the number of features (e.g., the 70 structural features).
		#        Tensor
		# src_mask -- the mask for the src sequence to prevent the model using 
		#             specific data point. For now, this should always be set 
		#             to None, because it isn't relevant to our application.
		#  			  Default, None. None or Tensor
		# OUTPUT
		# Returns a predicted value for log10(kcat)

		# Encode input
		# print ('Initial encoding')
		# print (f'src.shape: {src.shape}')
		src = self.input_encoder(src) * np.sqrt(self.d_model) # np.sqrt(self.input_size) commented-out 9/19/23
		# print (f'src.shape: {src.shape}\n\n')

		# Add positional encoding
		# print ('Positional encoding')
		# print (f'src.shape: {src.shape}')
		src = self.pos_encoder(src)
		# print (f'src.shape: {src.shape}\n\n')

		# Pass through transformer encoder
		# print ('Transformer encoding')
		# print (f'src.shape: {src.shape}')
		# start_enc = time.time()
		# enc1 = self.transformer_encoder(src)   ### doesn't work for 4D data
		# print (f'enc runtime: {time.time() - start_enc}')
		# print (f'enc1.shape: {enc1.shape}')

		"""	Rough, brute force way to handle 4D data:
			Just pass each batch one at a time, where each
			batch consists of path_set_size number of pathways.
			The build in transformer layers in PyTorch accept the 
			3D data of a single batch (but not 4D multiple batches).
			It's like you trick it into treating the different pathways
			as different, independent batches at this stage. We want
			independence of pathways at this stage, because their order 
			shouldn't matter, and a downstream pooling operation (or 
			other trainable operations we can think about later) will
			handle the simultaneous consideration of all pathways and 
			how they relate to one another 

			NOTE: the current brute force implementation actually works
			      quite well and is just as fast for processesing something
			      like [32, 10, 111, 512] as processing [320, 111, 512]

		"""
		# start_enc = time.time()
		# enc1 = torch.zeros(src.shape)
		# for i in range(src.shape[0]):
		# 	enc1[i,:,:,:] = self.transformer_encoder(src[i,:,:,:])
		# print (f'enc runtime: {time.time() - start_enc}')
		# print (f'enc1.shape: {enc1.shape}\n\n')


		"""
		Alternative method that involves re-shaping.
		However, I'm not certain the reshaping methods
		preserve the original order and specific structure
		of the data -- need to check that.

		However, in practice the above for-loop option
		seems to run faster, or at least it for sure isn't slower
		"""
		# convert src from 4D to 3D by stacking the first axis
		orig_shape = src.shape
		# print ('Transformer')
		# print (f'src.shape: {src.shape}')
		src = src.view(-1, orig_shape[-2], orig_shape[-1]) # double check that this is equivalent to vstacking
		# print (f'src.shape: {src.shape}')
		enc1 = self.transformer_encoder(src)
		# convert enc1 back to 4D from 3D; this recovers separate batches along first axis
		enc1 = enc1.view(-1, orig_shape[-3], orig_shape[-2], orig_shape[-1]) # double check that this is the inverse of vstacking and recovers the batches
		# print (f'enc1.shape: {enc1.shape}\n\n')


		# Do average pooling for each pathway across its time points
		# print (f'enc1.shape: {enc1.shape}')
		enc1 = torch.mean(enc1, 2)
		# print (f'enc1.shape: {enc1.shape}')


		# Take average across all paths in each observation (experiment with inclusion of other moments and/or max pooling)
		# print ('Averaging over paths')
		# print (f'enc1.shape: {enc1.shape}')
		enc = torch.mean(enc1, 1)
		# print (f'enc.shape: {enc.shape}\n\n')


		# Flatten each observation's averaged time series
		# print ('Flattening avg time series')
		# print (f'enc.shape: {enc.shape}')
		# enc = torch.flatten(enc, start_dim=1)
		# print (f'enc.shape: {enc.shape}\n\n')

		# Prediction head
		# print ('MLP prediction head')
		# print (f'enc.shape: {enc.shape}')
		out = self.mlp_head(enc)
		# print (f'out.shape: {out.shape}')
		# print (out, '\n\n')


		if self.task == 'kcat regression':
			return out
		elif self.task == 'NR/R binary classification':
			return self.sigmoid(out)
		elif self.task == 'S/F binary classification':
			return self.sigmoid(out)


class LSTMModel(nn.Module):
	# Encodes sets of multivariate time series with LSTM layers, 
	# pools the encodings, then uses the pooled encoding to predict
	# log(kcat) with an MLP prediction head

	def __init__(self, 
				 input_size: int,
				 lstm_hidden_size: int=256,
				 n_lstm_layers: int=2,
				 dropout_lstm: float=0.2,
				 bidirectional: bool=False,
				 d_mlp_head: int=128,
				 dropout_mlp_head: float=0.1,
				 task: str='kcat regression'):
		# INPUT:
		# input_size -- number of features in input. For example, 1 if univariate or 
		# 			    or 70 if using 70 structural features. int
		# lstm_hidden_size -- number of features in LSTM's hidden state
		# n_lstm_layers -- number of recurrent, stacked LSTM layers
		# dropout_lstm -- dropout for dropout layer applied to outputs of each LSTM
		#                 layer (except for the last LSTM layer)
		# bidirectional -- whether to use a bidirectional LSTM (True) or not (False)
		# d_mlp_head -- hidden layer size for the (middle layer) of the two-layer MLP
		#               regression head
		# dropout_mlp_head -- dropout rate applied in between the two layers in the 
		#                     MLP regression head
		# 
		#

		super().__init__()

		self.input_size = input_size
		self.model_type = 'PredictiveLSTMEncoder'
		self.task = task


		# LSTM encoder
		self.lstm_encoder = nn.LSTM(input_size=self.input_size, hidden_size=lstm_hidden_size,
									num_layers=n_lstm_layers, batch_first=True,
									dropout=dropout_lstm, bidirectional=bidirectional)

		# Prediction head (MLP layer)
		self.mlp_head = nn.Sequential(nn.Linear(in_features=lstm_hidden_size, out_features=d_mlp_head),
									  nn.ReLU(),
									  nn.Dropout(dropout_mlp_head),
									  nn.Linear(in_features=d_mlp_head, out_features=1))

		self.sigmoid = nn.Sigmoid() # used when self.task is for classification

	def forward(self, src: Tensor) -> Tensor:
		# INPUT
		# src -- the input data of shape [batch_size, path_set_size, timesteps, features] where
		#        batch_size is the number of observations per batch, path_set_size is the 
		# 		 number of paths per observation, timesteps is the number of time points 
		# 		 in each path, and features the number of features (e.g., the 70 structural
		# 		 features). Tensor
		#        Tensor
		# OUTPUT
		# Returns a predicted value for log10(kcat)

		# Pass through LSTM encoder
		# convert src from 4D to 3D by stacking the first axis (the batches)
		# print ('LSTM encoding:')
		# print (f'src.shape: {src.shape}')
		orig_shape = src.shape
		src = src.view(-1, orig_shape[-2], orig_shape[-1])
		# print (f'src.shape: {src.shape}')
		enc1, _ = self.lstm_encoder(src)
		# print (f'enc1.shape: {enc1.shape}')
		# convert enc1 back to 4D from 3D; this recovers separate batches along first axis
		enc1 = enc1.view(orig_shape[0], orig_shape[1], orig_shape[2], -1)
		# print (f'enc1.shape: {enc1.shape}\n')

		# Keep only the last time step's hidden state (which summarizes info from entire path)
		enc1 = enc1[:,:,-1,:]
		# print (f'enc1.shape: {enc1.shape}\n\n')

		# Take average across all paths in each observation (experiment with inclusion of other moments and/or max pooling)
		# print ('Averaging over paths')
		# print (f'enc1.shape: {enc1.shape}')
		enc = torch.mean(enc1, 1)
		# print (f'enc.shape: {enc.shape}\n\n')


		# Prediction head
		# print ('MLP prediction head')
		# print (f'enc.shape: {enc.shape}')
		out = self.mlp_head(enc)
		# print (f'out.shape: {out.shape}')
		# print (out, '\n\n')

		if self.task == 'kcat regression':
			return out
		elif self.task == 'NR/R binary classification':
			return self.sigmoid(out)
		elif self.task == 'S/F binary classification':
			return self.sigmoid(out)



"""
PyTorch class for adding positional encodings to input data; typically
used inside transformer architectures (see class TransformerModel for an example)
"""
class PositionalEncoding(nn.Module):
	# Implementation taken from PyTorch documentation at:
	# https://pytorch.org/tutorials/beginner/transformer_tutorial.html
	# INPUT:
	# d_model -- the dimension of the transformer encoder layers, this
	#            is the number of features in the input data after being 
	#            passed through the encoder layer. int
	# dropout -- fraction of neurons subjected to dropout. Default, 0.1.
	#			 float
	# max_len -- the dimensionality of the positional encoding array. 
	#            i.e., the array to be added to input is of shape 
	#            [max_len, 1, d_model], but only the first "input_size"
	#            rows will be added to input data. Here, "input_size"
	#            is the number of time points in the input data

    def __init__(self, d_model: int, dropout: float=0.1, max_len: int=500):
        super().__init__()
        self.dropout = nn.Dropout(p=dropout)

        position = torch.arange(max_len).unsqueeze(1)
        div_term = torch.exp(torch.arange(0, d_model, 2) * (-np.log(10000.0) / d_model))
        pe = torch.zeros(max_len, d_model)
        pe[:, 0::2] = torch.sin(position * div_term)
        pe[:, 1::2] = torch.cos(position * div_term)
        self.register_buffer('pe', pe)

    def forward(self, x: Tensor) -> Tensor:
        # INPUT:
        # x -- Tensor of form [seq_len, batch_size, embedding_dim], so 
        #      the data in x need to first be permuted to shift the batch
        #      dimension from axis 0 to axis 1 like so: x = x.permute(1, 0, 2)
        
        ### x = x + self.pe[:x.size(0)]
        
        """
		Can we do the below implementation instead? And require the the 
		second-to-last axis corresponds to the time points?
        """
        # print (f'x.shape: 		{x.shape}')
        # print (f'self.pe.shape: {self.pe.shape}')
        # print (f'self.pe[0:x.size(-2),:].shape: {self.pe[0:x.size(-2),:].shape}\n')
        x = x + self.pe[0:x.size(-2),:]

        return self.dropout(x)



"""
Classes and functions related to calculating loss
"""
class DenseLoss(nn.Module):
    # Implements the DenseLoss loss function using DenseWeight
	# method (and object) as described here:
	# https://link.springer.com/article/10.1007/s10994-021-06023-5
	
	def __init__(self, dw):
		# INPUT:
		# dw -- an instance of DenseWeight that has been fit to data
		#    	by running its .fit() method
		super().__init__()
		self.dw = dw
	
	def forward(self, preds, targets):
		# Calculate relevance (weight) for each sample

		weights = torch.from_numpy( self.dw(targets.cpu().numpy()) ).to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))

		# Calculate weighted MSE
		err = torch.pow(preds - targets, 2)
		err_weighted = weights * err
		mse = err_weighted.mean()

		return mse

def define_loss(model, dw=None):
	# Defines the loss function based on the model's prediction task, 
	# and whether loss weighting with DenseWeight is activated
	# INPUT:
	# model -- instance of TransformerModel
	# dw -- instance of DenseWeight or None. If None (default),
	#		then DenseWeight and DenseLoss are not applied, and 
	# 		observations' loss terms are weighted equally

	if (model.task == 'kcat regression') and (dw == None):
		loss_fn = nn.MSELoss()
	elif model.task == 'kcat regression':
		loss_fn = DenseLoss(dw)
	elif model.task == 'NR/R binary classification':
		loss_fn = nn.BCELoss()
	elif model.task == 'S/F binary classification':
		loss_fn = nn.BCELoss()

	return loss_fn

def plot_dw_alpha(pathdataset, alphas=[0, 0.5, 0.90, 0.95, 1.0], figsize=(16,8), figname=False):
	# Plot weights vs. log10(kcat) for different alpha
	# INPUT
	# pathdataset -- PathDataset object with the .obs attribute
	#				 populated. Or, a PyTorch DataLoader object 
	#				 constructed on a PathDataset object
	# alphas -- the DenseWeight alpha values with which to calculate
	#			weights for each kcat in pathdataset.obs.kcat
	# figsize -- figure size
	# figname -- file to which to save the plot

	if isinstance(pathdataset, PathDataset):
		kcats = np.log10(pathdataset.obs.kcat)

	elif isinstance(pathdataset, DataLoader):
		kcats = []
		for batch_idx, batch in enumerate(pathdataset):
			kcats.append(batch['kcat'].detach().cpu().numpy())
		kcats = np.concatenate(kcats)

	weights = {}
	df = pd.DataFrame(kcats, columns=['kcat'])
	df['bins'] = pd.cut(df['kcat'], bins=5)
	x = np.linspace(np.min(kcats), np.max(kcats), 100)
	for a in alphas:
		dw = DenseWeight(alpha=a, eps=1e-6, bandwidth=1)
		dw.fit(kcats)
		weights[a] = dw(x)
		df[f'weights (a={a})'] = dw(df['kcat'].to_numpy())

	# Plot
	fig, axes = plt.subplots(2, 3, figsize=figsize)
	for i,a in enumerate(weights):
		axes.flatten()[0].plot(x, weights[a], label=fr'$\alpha={a}$')
		
		ax = axes.flatten()[i+1]
		print (df)
		weight_sum = df.groupby(by='bins').apply(lambda x: np.sum(x[f'weights (a={a})'].to_numpy()))
		print (weight_sum)
		weight_sum.plot.bar(x='bins', ax=ax, title=fr'$\alpha={a}$')
		if (i+1) == len(weights):
			for tick in ax.get_xticklabels():
				tick.set_rotation(45)
				tick.set_fontsize=9
		else:
			ax.set_xticklabels(ax.get_xticks(), rotation=45)
		ax.set_ylabel('Sum of weights')
		print ('\n\n')

	axes.flatten()[0].hist(kcats, label=r'$p(log_{10}(k_{cat}))$', density=True)
	axes.flatten()[0].legend(fontsize=9)
	# axes.flatten()[0].set_xlabel(r'$log_{10}(k_{cat})$')
	fig.text(0.5, 0.02, r'$log_{10}(k_{cat})$', ha='center', fontsize=20)
	fig.tight_layout()
	fig.savefig(figname)

	return



"""
Functions related to learning rate schedules
"""
def warmup_decay_lr(step, d_model=256, warmup_steps=4000):
	# Learning rate schedule based on that used in Attention is All You Need:
	# https://arxiv.org/pdf/1706.03762.pdf
	# An adjustment was made to account for the lower-dimensional models
	# used in the default TransformerModel module. Specifically, the original 
	# schedule from Attention is All You Need is multiplied by a factor
	# of 1/sqrt(2) because the dimension of our default TransformerModel 
	# (dmodel) is half that of models used in Attention is All You Need.
	# INPUT:
	# step -- the training step count. Each training batch and update of 
	# 		  learned parameters is considered a single step. int
	# d_model -- the dimensions of the transformer encoder layers in the 
	#            transformer encoder. All sublayers in the model will produce
	#            outputs with this dimension. int
	# warmup_steps -- the number of warmup steps to use. int

	if step == 0:
		return 0

	term1 = step**-0.5
	term2 = step*warmup_steps**-1.5
	term = np.array([term1,term2])

	lr = (2*d_model)**-0.5 * np.min(term, axis=0)

	return lr



"""
Classes and functions related to model training and evaluation
"""
class Fold():
	# Object for storing information specific to different CV folds and 
    # for executing training and testing loops for a given fold
	# For information on input, see head of transformer_1.py or 
	# lstm_1.py if model_type equals 'transformer encoder' or 
	# 'lstm encoder', respectively

	def __init__(self, cv_fold, traindata, testdata, parallel_folds, 
	      		 output_text_filename, model_kwargs, device, 
				 stoch_labels, dw_settings, control_model, epochs,
				 random_seed, batch_size, cv_folds, regularization=None,
				 model_type='transformer encoder',
				 train_idxs=None, test_idxs=None, warmup_steps=4000):
		self.cv_fold = cv_fold
		self.traindata = traindata
		self.train_idxs = train_idxs
		self.testdata = testdata
		self.test_idxs = test_idxs
		self.parallel_folds = parallel_folds
		self.output_text_filename = output_text_filename
		self.model_kwargs = model_kwargs
		self.device = device
		self.stoch_labels = stoch_labels
		self.dw_settings = dw_settings
		self.control_model = control_model
		self.epochs = epochs
		self.random_seed = random_seed
		self.batch_size = batch_size
		self.cv_folds = cv_folds
		self.regularization = regularization
		self.model_type = model_type
		self.warmup_steps = warmup_steps
		
	def run(self):
        # If running folds in parallel, give each a unique output file
		if not self.parallel_folds:
			self.fold_output_text = open(self.output_text_filename, 'a')
		else:
			self.fold_output_text = open(f'{self.output_text_filename}-fold{self.cv_fold}', 'w')
		
		# Define a new model
		if self.model_type == 'transformer encoder':
			print ('Building TransformerModel')
			self.fold_output_text.write('Building TransformerModel\n')
			self.model = TransformerModel(**self.model_kwargs).to(self.device)
		elif self.model_type == 'LSTM encoder':
			print ('Buidling LSTMModel')
			self.fold_output_text.write('Building LSTMModel\n')
			self.model = LSTMModel(**self.model_kwargs).to(self.device)
			
		total_params = sum(p.numel() for p in self.model.parameters())
		trainable_params = sum(p.numel() for p in self.model.parameters() if p.requires_grad)
		print (f'Total parameters:     {total_params}')
		print (f'Trainable parameters: {trainable_params}')
		self.fold_output_text.write(f'Total parameters:     {total_params}\n')
		self.fold_output_text.write(f'Trainable parameters: {trainable_params}\n')
		
		# Fit the scaler to the training data
		scaler = NormalScaler()
		if self.train_idxs is None:
			scaler.fit(self.traindata.data)
		else:
			scaler.fit(self.traindata.data[np.concatenate(self.traindata.obs.obs[self.train_idxs]),:,:])
		train_data_scaler = DataScaler(scaler, stoch_labels=self.stoch_labels)
		test_data_scaler  = DataScaler(scaler, stoch_labels=False)

		# Fit weighting function to the training data, if weighted loss is activated
		if self.dw_settings != None:
			if self.model.task != 'kcat regression':
				raise ValueError("DenseLoss is only implemented for task='kcat regression'."+\
                                 "You cannot specify dw_settings for other tasks.")
			dw = DenseWeight(alpha=self.dw_settings['alpha'],
							 bandwidth=self.dw_settings['bandwidth'],
							 eps=self.dw_settings['eps'])
			if self.train_idxs is None:
				dw.fit(np.log10(self.traindata.obs.kcat))
			else:
				dw.fit(np.log10(self.traindata.obs.kcat[self.train_idxs]))
		else: 
			dw = None
				
		# Define loss, optimizer, and a learning rate scheduler
		self.loss_fn = define_loss(self.model, dw)
		self.optimizer = torch.optim.Adam(self.model.parameters(), lr=1) # lr will be scaled and set by scheduler
		if self.model_type == 'transformer encoder':
			d_model = self.model_kwargs['d_model']
		elif self.model_type == 'LSTM encoder':
			d_model = self.model_kwargs['lstm_hidden_size']
		self.scheduler = torch.optim.lr_scheduler.LambdaLR(self.optimizer, 
						 lambda x: warmup_decay_lr(x, d_model=d_model, warmup_steps=self.warmup_steps))
		
		# Define datasets and dataloaders for train and test sets
		train_dataset = PathTorchDataset(self.traindata, elligible_idxs=self.train_idxs, transform=train_data_scaler, control_model=self.control_model)
		test_dataset  = PathTorchDataset(self.testdata, elligible_idxs=self.test_idxs, transform=test_data_scaler)
		train_variants = np.unique(train_dataset.pathdataset.obs.variant[train_dataset.elligible_idxs])
		test_variants = np.unique(test_dataset.pathdataset.obs.variant[test_dataset.elligible_idxs])
		
		print ('\n\nTraining variants:')
		print (train_variants, '\n\n')
		self.fold_output_text.write('\n\nTraining variants:\n')
		self.fold_output_text.write(str(train_variants))
		self.fold_output_text.write('\n\n\n')
		self.fold_output_text.flush()
		
		best_val_loss = float('inf')
		best_model_file = f'best_model_cvfold{self.cv_fold}.pt'
		for epoch in range(1, (self.epochs+1)):
			
			self.epoch = epoch
			start_epoch = time.time()
			
			# initialize data loading, explicitly seed random number generators for reproducibility
			train_rng, test_rng = torch.Generator(), torch.Generator()
			train_rng.manual_seed(int(self.random_seed*1e10/41/epoch*self.cv_fold))
			test_rng.manual_seed(int(self.random_seed*1e10/79/epoch*self.cv_fold))
			self.train_loader = DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True, generator=train_rng)
			self.test_loader  = DataLoader(test_dataset, batch_size=self.batch_size, shuffle=True, generator=test_rng)
			
			# train and test model
			self.train()
			val_results = self.evaluate()
			
			# report results
			epoch_duration = time.time() - start_epoch
			loss, avg_loss, avg_reg_loss = val_results['total loss'], val_results['avg loss'], val_results['avg reg_loss']
			acc, auroc = val_results['avg acc'], val_results['auroc']
			print ('\n\n','-'*80)
			self.fold_output_text.write('\n\n'+'-'*80+'\n')
			
			if self.model.task == 'kcat regression':
				print (f'End of epoch {self.epoch} | CV fold {self.cv_fold}/{self.cv_folds} | '
                       f'time: {epoch_duration:.1f}s | '
					   f'valid reg_loss {avg_reg_loss:.3f} | '
                       f'valid loss (MSE) {avg_loss:.3f} | RMSE {avg_loss**0.5:.3f}')
				
				self.fold_output_text.write(f'End of epoch {self.epoch} | CV fold {self.cv_fold}/{self.cv_folds} | '
                                       f'time {epoch_duration:.1f}s | '
									   f'valid reg_loss {avg_reg_loss:.3f} | '
                                       f'valid loss (MSE) {avg_loss:.3f} | RMSE {avg_loss**0.5:.3f}\n')
			
			elif self.model.task in ['NR/R binary classification', 'S/F binary classification']:
				print (f'End of epoch {self.epoch} | CV fold {self.cv_fold}/{self.cv_folds} | '
                       f' time: {epoch_duration:.1f}s | '
					   f'valid reg_loss {avg_reg_loss:.3f} | '
                       f'valid loss {avg_loss:.3f} | '
                       f'accuracy {acc:.5f} | '
					   f'auroc {auroc:.5f}')
				
				self.fold_output_text.write(f'End of epoch {self.epoch} | CV fold {self.cv_fold}/{self.cv_folds} | '
                                    f'time {epoch_duration:.1f}s | '
									f'valid reg_loss {avg_reg_loss:.3f} | '
                                    f'valid loss {avg_loss:.3f} | '
				    				f'accuracy {acc:.5f} | '
                                    f'auroc {auroc:.5f}\n')
			
			print ('\nValidation variants:')
			print (test_variants)
			self.fold_output_text.write('\nValidation variants:\n')
			self.fold_output_text.write(str(test_variants))
			self.fold_output_text.write('\n')
			
			# save the epoch's model
			if (epoch%5 == 0) or (epoch == 1):
				torch.save(self.model.state_dict(), f'model_epoch{epoch}_cvfold{self.cv_fold}.pt')
			if avg_loss < best_val_loss:
				print (f'\nBest loss achieved, saving model state to {best_model_file}')
				self.fold_output_text.write(f'\nBest loss achieved, saving model state to {best_model_file}\n')
				best_val_loss = avg_loss
				torch.save(self.model.state_dict(), best_model_file)
                # to load into model again later:
                # model.load_state_dict(torch.load(best_model_file))
			
			print ('-'*80, '\n\n')
			self.fold_output_text.write('-'*80+'\n\n\n')
			self.fold_output_text.flush()
		
		# if parallel_folds:
		self.fold_output_text.close()

	def reg_loss(self):
		# Generates the penalization term. If self.regularization is None, this
		# penalty is 0. If self.regularization is not None, it can specify either 
		# L1 or L2 loss and the coefficient lambda via a dictionary. E.g.,
		# self.regularization = {'l1':0.01} 
		# returns L1 loss with lambda factor of 0.01
	
		if self.regularization is None:
			return torch.tensor(0., requires_grad=True)
		
		elif list(self.regularization.keys())[0].lower() == 'l1':
			lam = float(list(self.regularization.values())[0])

			# l1_term = torch.tensor(0., requires_grad=True)
			# for name, weights in self.model.named_parameters():
			# 	if 'bias' not in name:
			# 		l1_term += torch.sum(torch.abs(weights))

			# l1_term = sum(p.abs().sum() for p in self.model.parameters())
			l1_term = sum(p.abs().sum() for name,p in self.model.named_parameters() if 'bias' not in name)


			return lam*l1_term
		
		elif list(self.regularization.keys())[0].lower() == 'l2':
			lam = float(list(self.regularization.values())[0])
			l2_term = sum(p.pow(2.0).sum() for name,p in self.model.named_parameters() if 'bias' not in name)

			return lam*l2_term
	
	def train(self) -> None:
		# Training function. Call this once for every epoch to run
		# through the data in dataloader and update the model parameters
		# INPUT:
		# model -- an instance of a PyTorch nn.Module
		# dataloader -- PyTorch DataLoader to stream training data
		# output_text -- open file to which output will be written

		self.model.train()
		total_loss, total_reg_loss, total_acc = 0.0, 0.0, 0.0
		start_time = time.time()
		log_interval = 25 # print info every log_interval number of batches
		batch_count = 0

		for batch_idx, batch in enumerate(self.train_loader):

			# forward pass
			output = self.model(batch['paths'])

			# print (type(output), output, output.dtype)
			# print (type(batch['kcat'].view(-1,1)), batch['kcat'].view(-1,1), batch['kcat'].view(-1,1).dtype)

			if self.model.task == 'kcat regression':
				loss = self.loss_fn(output, batch['kcat'].view(-1,1))
				reg_loss = loss + self.reg_loss()
			elif self.model.task == 'NR/R binary classification':
				loss = self.loss_fn(output, batch['order'].view(-1,1))
				reg_loss = loss + self.reg_loss()
				acc = (output.round() == batch['order'].view(-1,1)).float().mean()
				total_acc += acc
			elif self.model.task == 'S/F binary classification':
				loss = self.loss_fn(output, batch['kcat_class'].view(-1,1))
				reg_loss = loss + self.reg_loss()
				acc = (output.round() == batch['kcat_class'].view(-1,1)).float().mean()
				total_acc += acc

			# backward pass
			self.optimizer.zero_grad()
			reg_loss.backward()
			# torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5) # uncomment to help prevent gradients from exploding
			# more info: https://pytorch.org/tutorials/beginner/transformer_tutorial.html

			# update weights
			self.optimizer.step()

			# update loss 
			total_loss += loss.item()
			total_reg_loss += reg_loss.item()

			# update batch count, which is reset to 0 after printing progress
			batch_count += 1


			if ((batch_idx+1) % log_interval == 0) or ((batch_idx+1) == len(self.train_loader)):
				
				# print progress and info
				time_per_batch = (time.time() - start_time) / batch_count
				current_loss = total_loss / batch_count
				current_reg_loss = total_reg_loss / batch_count 
				current_acc = total_acc / batch_count # only reported when task is '* classification'
				root_loss = np.sqrt(current_loss)
				root_reg_loss = np.sqrt(current_reg_loss)
				curr_lr = self.scheduler.get_last_lr()[0]

				if self.model.task == 'kcat regression':
					print (f'epoch {self.epoch} | CV fold {self.cv_fold}/{self.cv_folds} | {batch_idx+1:d}/{len(self.train_loader):d} batches | '
							f'lr {curr_lr:0.3e} | seconds/batch {time_per_batch:.3f} | '
							f'loss {current_loss:.3e} | sqrt(loss) {root_loss:.3e} | reg_loss {current_reg_loss:.3e} | sqrt(reg_loss) {root_reg_loss:.3e}')
					self.fold_output_text.write(f'epoch {self.epoch} | CV fold {self.cv_fold}/{self.cv_folds} | {batch_idx+1:d}/{len(self.train_loader):d} batches | '
							f'lr {curr_lr:0.3e} | seconds/batch {time_per_batch:.3f} | '
							f'loss {current_loss:.3e} | sqrt(loss) {root_loss:.3e} | reg_loss {current_reg_loss:.3e} | sqrt(reg_loss) {root_reg_loss:.3e}\n')

				elif self.model.task in ['NR/R binary classification', 'S/F binary classification']:
					print (f'epoch {self.epoch} | CV fold {self.cv_fold}/{self.cv_folds} | {batch_idx+1:d}/{len(self.train_loader):d} batches | '
							f'lr {curr_lr:0.3e} | seconds/batch {time_per_batch:.3f} | '
							f'loss {current_loss:.3e} | sqrt(loss) {root_loss:.3e} | reg_loss {current_reg_loss:.3e} | sqrt(reg_loss) {root_reg_loss:.3e} | '
							f'acc {current_acc:.5f}')
					self.fold_output_text.write(f'epoch {self.epoch} | CV fold {self.cv_fold}/{self.cv_folds} | {batch_idx+1:d}/{len(self.train_loader):d} batches | '
							f'lr {curr_lr:0.3e} | seconds/batch {time_per_batch:.3f} | '
							f'loss {current_loss:.3e} | sqrt(loss) {root_loss:.3e} | reg_loss {current_reg_loss:.3e} | sqrt(reg_loss) {root_reg_loss:.3e} | '
							f'acc {current_acc:.5f}\n')

					total_acc = 0.0

				self.fold_output_text.flush()

				# reset loss, timer, and batch_count for next round of log_interval number of batches
				total_loss = 0.0
				total_reg_loss = 0.0
				start_time = time.time()
				batch_count = 0


			# update learning rate
			self.scheduler.step()
			
	def evaluate(self) -> float:
		# Model evaluation function. Typically, this is to be
		# executed at the end of every epoch to report the 
		# model performance on held out data
		# INPUT:
		# model -- an instance of a PyTorch nn.Module
		# dataloader -- PyTorch DataLoader to stream validation
		#               or testing data
		# RETURNS:
		# A dictionary with 'total loss' and 'avg loss' items,
		# where the 'avg loss' is the MSE, and the total loss 
		# is the sum of the SE over all observations in dataloader

		self.model.eval()
		total_loss, total_acc = 0.0, 0.0
		total_obs = 0
		total_preds, total_labels = [], []
		with torch.no_grad():
			for batch_idx, batch in enumerate(self.test_loader):
				n_obs = batch['paths'].size(0)

				output = self.model(batch['paths'])

				if self.model.task == 'kcat regression':
					labels = batch['kcat'].view(-1,1)
					loss = self.loss_fn(output, labels)

				elif self.model.task == 'NR/R binary classification':
					labels = batch['order'].view(-1,1)
					loss = self.loss_fn(output, labels)
					acc = (output.round() == labels).float().mean()
					total_acc += acc * n_obs

				elif self.model.task == 'S/F binary classification':
					labels = batch['kcat_class'].view(-1,1)
					loss = self.loss_fn(output, labels)
					acc = (output.round() == labels).float().mean()
					total_acc += acc * n_obs

				total_loss += loss.item() * n_obs
				total_obs += n_obs

				total_preds.append(output.cpu().numpy())
				total_labels.append(labels.cpu().numpy())

		# If doing classification, report the AUROC
		if 'classification' in self.model.task:
			auroc = AUROC(np.concatenate(total_labels), np.concatenate(total_preds))
		else:
			auroc = None

		avg_loss = total_loss / total_obs # this is equivalent to MSE when doing 'kcat regression' task
		avg_reg_loss = avg_loss + self.reg_loss()
		avg_acc  = total_acc / total_obs # this will be 0 when doing 'kcat regression' task

		return {'total loss':total_loss, 'avg loss':avg_loss, 'avg acc':avg_acc, 'auroc':auroc, 'avg reg_loss': avg_reg_loss}

"""
Classes for further, more in-depth evaluation of models post-training
"""
class LogFile():
    """
    Given the output_text file filename (str) generated by transformer_1.py, 
    this class parses the file and contains functions to plot model performance 
    during training. Typical usage to plot RMSE across batches and epochs:
    log = LogFile('transformer_1_output.txt')
    log.plot_summary()
    """
    
    def __init__(self, filename, figname=False):
        # INPUT
        # filename -- name of output_text file. str
        # figname -- name of file to save output figure to
        self.task = 'kcat regression' # default task if unspecified in config file
        self.filename = filename
        self.config = glob(f'{os.path.dirname(os.path.abspath(self.filename))}/*config*')[0]
        with open(self.config, 'r') as f:
            settings = f.readlines()
            settings = [l for l in settings if l[0] != '#']
            settings = ''.join(settings)

        if 'NR/R binary classification' in settings:
            self.task = 'NR/R binary classification'
        elif 'kcat regression' in settings:
            self.task = 'kcat regression'
        elif 'S/F binary classification' in settings:
            self.task = 'S/F binary classification'

        self.figname = figname
        
        batches, epochs = [], []
        with open(self.filename, 'r') as f:
            
            for line in f:
                if len(line.rsplit()) == 0: continue
                if line.rsplit()[0] == 'epoch':
                    batches.append(line)
                elif line.rsplit()[0] == 'End':
                    epochs.append(line)

		# store epochs log in DataFrame
        self.epoch_cols = [self.format(v) for v in epochs[0].split(' | ')]
        tmp = tempfile.TemporaryFile(mode='w+t')
        tmp.writelines(epochs)
        tmp.seek(0)
        self.epochs = self.clean_epoch_table(pd.read_csv(tmp, sep='|', names=self.epoch_cols))
        tmp.close()
        
        # store batches log in DataFrame
        self.batch_cols = [self.format(v) for v in batches[0].split(' | ')]
        tmp = tempfile.TemporaryFile(mode='w+t')
        tmp.writelines(batches)
        tmp.seek(0)
        self.batches = self.clean_batch_table(pd.read_csv(tmp, sep='|', names=self.batch_cols))
        tmp.close()
	
    def format(self, v):
        v = [i for i in v if ((not i.isdigit()) and i not in ['.','/','\n'])]
        if v[-1] == ' ': v.pop(-1)
        if v[0] == ' ': v.pop(0)
        v = ''.join(v).replace(' (MSE)','').replace(' e-','').replace(' e+','')
        v = v.replace('secondsbatch','seconds/batch')
        v = v.replace('End of epoch', 'epoch')
        return v

    def clean_epoch_table(self, epochs):
        
        epochs['epoch'] = [x.replace('End of epoch ','') for x in epochs['epoch']]
        epochs['CV fold'] = [x.split('fold ')[-1].split('/')[0] for x in epochs['CV fold']]
        epochs['time s'] = [x.split('time ')[-1].split('time: ')[-1].split('s')[0] for x in epochs['time s']]
        
        if self.task == 'kcat regression':
            epochs['valid loss'] = [x.split('MSE) ')[-1] for x in epochs['valid loss']]
            epochs['RMSE'] = [x.split('RMSE ')[-1].split('s')[0] for x in epochs['RMSE']]
        elif self.task in ['NR/R binary classification', 'S/F binary classification']:
            epochs['valid loss'] = [x.split('valid loss ')[-1] for x in epochs['valid loss']]
            epochs['valid reg_loss'] = [x.split('valid reg_loss ')[-1] for x in epochs['valid reg_loss']]
            epochs['accuracy'] = [x.split('accuracy ')[-1] for x in epochs['accuracy']]
            if str(epochs['auroc'][0]) == 'nan':
                # AUROC wasn't calculated for this job
                epochs.drop(columns=['auroc'])
            else:
                epochs['auroc'] = [x.split('auroc ')[-1] for x in epochs['auroc']]
        
        return epochs.apply(pd.to_numeric)
    
    def clean_batch_table(self, batches):
        
        batches['epoch'] = [x.replace('epoch ','') for x in batches['epoch']]
        batches['CV fold'] = [x.split('fold ')[-1].split('/')[0] for x in batches['CV fold']]
        batches['batches'] = [x.split('/')[0] for x in batches['batches']]
        batches['lr'] = [x.split('lr ')[-1] for x in batches['lr']]
        batches['seconds/batch'] = [x.split('batch ')[-1] for x in batches['seconds/batch']]
        batches['loss'] = [x.split('loss ')[-1] for x in batches['loss']]
        batches['sqrt(loss)'] = [x.split('loss) ')[-1] for x in batches['sqrt(loss)']]
        batches['reg_loss'] = [x.split('loss ')[-1] for x in batches['reg_loss']]
        batches['sqrt(reg_loss)'] = [x.split('loss) ')[-1] for x in batches['sqrt(reg_loss)']]
        if self.task in ['NR/R binary classification', 'S/F binary classification']:
            batches['acc'] = [x.split('acc ')[-1] for x in batches['acc']]

            if 'auroc' in batches.columns:
                if str(batches['auroc'][0]) == 'nan':
                    # AUROC wasn't calculated for this job
                    batches.drop(columns=['auroc'])
                else:
                    batches['auroc'] = [x.split('auroc ')[-1] for x in batches['auroc']]

        return batches.apply(pd.to_numeric)
	
    def cv_summary(self, log=False, shade_err=False, metric='loss'):
		# Plot training curves for each CV fold
        # log sets log scale for y-axis when True
        # shade_err shades +/- 1STD across batches in each epoch for training loss

        n_folds = np.unique(self.epochs['CV fold']).shape[0]
        if n_folds in [5,10]:
            ncols = 5
        else:
            ncols = 3
        nrows = int(np.ceil(n_folds/ncols))
        fig, axes = plt.subplots(nrows, ncols, figsize=(6.4*ncols,4.8*nrows))
		
        for i,fold in enumerate(np.arange(n_folds)+1):
            tmp_batches = self.batches.loc[self.batches['CV fold'] == fold]
            avg_batches = tmp_batches.groupby('epoch').mean()
            std_batches = tmp_batches.groupby('epoch').std()
			
            tmp_epochs = self.epochs.loc[self.epochs['CV fold'] == fold]
            ax = axes.flatten()[i]
            ax.plot(avg_batches.index, avg_batches[metric], label='Train', color='k', alpha=0.8)
            if shade_err:
                ax.fill_between(std_batches.index, avg_batches[metric]-std_batches[metric], avg_batches[metric]+std_batches[metric], color='k', alpha=0.3)
            ax.plot(tmp_epochs['epoch'], tmp_epochs['valid loss'], label='Test', color='b', alpha=0.8)

            ax.set_xlabel('Epoch', fontsize=20)
            ax.set_ylabel('Loss', fontsize=20)
            ax.set_title(f'Fold {fold}', fontsize=20)
            ax.tick_params(axis='both', labelsize=16)
            ax.legend(fontsize=20)

            # ax.set_ylim((0,5))

            if log:
                ax.set_yscale('log')

        fig.tight_layout()
        if self.figname:
            fig.savefig(self.figname, dpi=300)
        plt.show()


class ModelTest(PathDataset):
    # Class that organizes a model and dataset for execution of
    # various model performance analyses
    
    def __init__(self, model_file, data_file, model_kwargs, meta_file=None,
				 output_file=None, scaler=None, features=['*'], task='kcat regression'):
        
        super().__init__(data_file, meta_file=meta_file, path_set_size=1, features=features)
        self.scaler = scaler
        self.model_file = model_file
        self.config_file = glob('/'.join(model_file.split('/')[0:-1]) + '/*conf*txt')[0]
        self.train_vars, self.test_vars = ModelTest.get_val_variants(model_file, output_file=output_file)
        self.model_kwargs = model_kwargs
        self.task = task
        
        # Create train indexes corresponding to variants in the train set
        train_idx = np.nonzero(np.in1d(np.array(self.meta.variant),np.unique(self.train_vars)))[0]

        # Load the model
        #self.model = TransformerModel(self.data.shape[-1], self.data.shape[-2], d_model=128) ### read d_model from config file
        self.model = self.make_model()
        self.model.load_state_dict(torch.load(self.model_file))

        # Fit the scaler to the training data
        if self.scaler == None:
            self.scaler = NormalScaler()
            self.scaler.fit(self.data[train_idx,:,:])
            self.data_scaler = DataScaler(self.scaler)
        else:
            self.data_scaler = DataScaler(self.scaler)
        
        # Initialize some variables that can later be populated with data
        self.variants, self.preds, self.targets = None, None, None
        
    def make_model(self):
        # Creates the PyTorch model object into which pre-trained
        # weights are loaded
        model = TransformerModel(**self.model_kwargs).to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))
        return model
    
    def score_var(self, var):
        
        var_idx = np.nonzero(np.in1d(np.array(self.obs.variant), var))[0]
        var_dataset = PathTorchDataset(self, elligible_idxs=var_idx, transform=self.data_scaler)

        loader = DataLoader(var_dataset, batch_size=32, shuffle=True)

        self.model.eval()
        total_obs = 0
        with torch.no_grad():
            
            results = []
            for batch_idx, batch in enumerate(loader):

                n_obs = batch['paths'].size(0)
                output = self.model(batch['paths']).cpu().numpy().reshape((-1))
                total_obs += n_obs
                # self.results[var][path_set_size].append(output)
                results.append(output)
    
        return results
        
    def plot_test_var_pred(self, path_set_sizes=[10,100,1000], figname=False):
        # Plots the distribution of predicted log(kcat) values 
        # for each held-out (i.e., validation) variant as 
        # function of the path_set_size, which is the number of
        # paths included in each observation of the variant
        
        results = {}
        for var in self.test_vars:
            d = {}
            for size in path_set_sizes:
                d[size] = []
            results[var] = d
            
        for path_set_size in path_set_sizes:
            
            print (f'Testing path_set_size: {path_set_size}')
            self.path_set_size = path_set_size
            
            # Populate the obs attribute
            self.make_observations()
            
            # grab indexes of the held-out variants
            for i,var in enumerate(np.unique(self.test_vars)):
                res = self.score_var(var)
                results[var][path_set_size] = res
                print (f'Completed {i+1}/{self.test_vars.shape[0]} variants...')
            print ()
            
            # Empty the obs attribute to reset it
            self.obs = None     
            
        for var in results:
            for size in results[var]:
                results[var][size] = np.concatenate(results[var][size])
                
        # Plot
        ncols = 3
        nrows = int(np.ceil(len(results)/ncols))
        fig, axes = plt.subplots(nrows, ncols, figsize=(9*ncols,6*nrows))
        for i,var in enumerate(results):

            var_kcat = np.log10(self.meta.kcat[np.where(np.array(self.meta.variant) == var)[0][0]])
            if self.task == 'S/F binary classification':
                var_kcat = 1 if var_kcat > -16.02 else 0

            path_set_sizes, y_pred = [],[]
            for path_set_size in results[var]:

                data = results[var][path_set_size]
                y_pred += list(data)
                path_set_sizes += [path_set_size]*data.shape[0]


            df = pd.DataFrame({'path_set_size': path_set_sizes, 'Pred. log(kcat)': y_pred})

            # Create violin plot with seaborn
            axes.flatten()[i] = sns.violinplot(data=df, x='path_set_size', y='Pred. log(kcat)', ax=axes.flatten()[i])
            axes.flatten()[i].axhline(var_kcat, ls='--', c='gray', label=r'TIS log($k_{cat}$)')
            axes.flatten()[i].set_xlabel('')
            axes.flatten()[i].set_ylabel('')
            axes.flatten()[i].set_title(var, fontsize=22)
            axes.flatten()[i].legend(fontsize=20)
            axes.flatten()[i].tick_params(axis='both', labelsize=22)
            if self.task == 'S/F binary classification':
                axes.flatten()[i].set_ylim((-0.01,1.01)) 
        fig.text(0.5, 0.07, 'Paths per prediction', ha='center', fontsize=32)
        fig.text(0.05, 0.5, r'Predicted log($k_{cat}$)', va='center', rotation='vertical', fontsize=32)

        # fig.tight_layout()
        if figname:
            fig.savefig(figname, dpi=300)
        
        return results
    
    def plot_train_var_pred(self, path_set_sizes=[10,100,1000], figname=False):
        # Plots the distribution of predicted log(kcat) values 
        # for each variant included during training as a 
        # function of the path_set_size, which is the number of
        # paths included in each observation of the variant
        
        results = {}
        for var in self.train_vars:
            d = {}
            for size in path_set_sizes:
                d[size] = []
            results[var] = d
            
        for path_set_size in path_set_sizes:
            
            print (f'Testing path_set_size: {path_set_size}')
            self.path_set_size = path_set_size
            
            # Populate the obs attribute
            self.make_observations()
            
            # grab indexes of the held-out variants
            for i,var in enumerate(np.unique(self.train_vars)):
                res = self.score_var(var)
                results[var][path_set_size] = res
                print (f'Completed {i+1}/{self.train_vars.shape[0]} variants...')
            print ()
            
            # Empty the obs attribute to reset it
            self.obs = None     
            
        for var in results:
            for size in results[var]:
                results[var][size] = np.concatenate(results[var][size])
                
        # Plot
        ncols = 3
        nrows = int(np.ceil(len(results)/ncols))
        fig, axes = plt.subplots(nrows, ncols, figsize=(9*ncols,6*nrows))
        for i,var in enumerate(results):

            var_kcat = np.log10(self.meta.kcat[np.where(np.array(self.meta.variant) == var)[0][0]])
            if self.task == 'S/F binary classification':
                var_kcat = 1 if var_kcat > -16.02 else 0

            path_set_sizes, y_pred = [],[]
            for path_set_size in results[var]:

                data = results[var][path_set_size]
                y_pred += list(data)
                path_set_sizes += [path_set_size]*data.shape[0]


            df = pd.DataFrame({'path_set_size': path_set_sizes, 'Pred. log(kcat)': y_pred})

            # Create violin plot with seaborn
            axes.flatten()[i] = sns.violinplot(data=df, x='path_set_size', y='Pred. log(kcat)', ax=axes.flatten()[i])
            axes.flatten()[i].axhline(var_kcat, ls='--', c='gray', label=r'TIS log($k_{cat}$)')
            axes.flatten()[i].set_xlabel('')
            axes.flatten()[i].set_ylabel('')
            axes.flatten()[i].set_title(var, fontsize=22)
            axes.flatten()[i].legend(fontsize=20)
            axes.flatten()[i].tick_params(axis='both', labelsize=22)
            if self.task == 'S/F binary classification':
                axes.flatten()[i].set_ylim((-0.01,1.01)) 
        fig.text(0.5, 0.07, 'Paths per prediction', ha='center', fontsize=32)
        fig.text(0.05, 0.5, r'Predicted log($k_{cat}$)', va='center', rotation='vertical', fontsize=32)

        # fig.tight_layout()
        if figname:
            fig.savefig(figname, dpi=300)
        
        return results
    
    def corr_test(self, verbose=False):
        # Calculate Pearson and Spearman correlation coefficients between predictions and 
        # TIS measured kcat values for variants in the test set
        
        # From https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.spearmanr.html:
        # Returns:
        # res -- a dictionary containing keys and values:
        #        'spearman': SignificanceResult returned by scipy.stats.spearmanr
        #        'pearson': PearsonRResult returned by scripy.stats.pearsonr
        #    See https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.spearmanr.html
        #        https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.pearsonr.html
        #    for more information on these returned objects
        

        # Populate the obs attribute
        self.make_observations()

        variants, preds, targets = [], [], []
        # grab indexes of the held-out variants
        for i,var in enumerate(np.unique(self.test_vars)):
            res = self.score_var(var)
            res = np.concatenate(res)

            variants.append(var)
            preds.append(np.mean(res))
            targets.append(np.log10(self.obs.kcat[np.where(self.obs.variant==var)[0][0]]))

            print (f'Completed {i+1}/{np.unique(self.test_vars).shape[0]} variants...')

        if verbose:
            for i,var in enumerate(variants):
                print (f'{var}: {preds[i]:.2f}   |   {targets[i]:.2f}')
            
            plt.figure()
            plt.scatter(preds, targets)
            plt.scatter(-16.02, -16.02, marker='x', color='k', label='WT')
            plt.plot(targets, targets, ls='--', color='gray', label=r'$x=y$')
            plt.xlabel('Predictions')
            plt.ylabel('Targets (TIS)')
            plt.title(self.model_file)
            plt.legend()
            plt.show()
        
        res = {}
        res['spearman'] = spearmanr(preds, targets)#, alternative='greater')
        res['pearson']  = pearsonr(preds, targets)

        return res
    
    def corr_train(self, verbose=False):
        # Calculate Pearson and Spearman correlation coefficients between predictions and 
        # TIS measured kcat values for variants in the train set
        
        # From https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.spearmanr.html:
        # Returns:
        # res -- a dictionary containing keys and values:
        #        'spearman': SignificanceResult returned by scipy.stats.spearmanr
        #        'pearson': PearsonRResult returned by scripy.stats.pearsonr
        #    See https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.spearmanr.html
        #        https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.pearsonr.html
        #    for more information on these returned objects
        

        # Populate the obs attribute
        self.make_observations()

        variants, preds, targets = [], [], []
        # grab indexes of the training variants
        for i,var in enumerate(np.unique(self.train_vars)):
            res = self.score_var(var)
            res = np.concatenate(res)

            variants.append(var)
            preds.append(np.mean(res))
            targets.append(np.log10(self.obs.kcat[np.where(self.obs.variant==var)[0][0]]))

            print (f'Completed {i+1}/{np.unique(self.train_vars).shape[0]} variants...')

        if verbose:
            for i,var in enumerate(variants):
                print (f'{var}: {preds[i]:.2f}   |   {targets[i]:.2f}')
        
        res = {}
        res['spearman'] = spearmanr(preds, targets)#, alternative='greater')
        res['pearson']  = pearsonr(preds, targets)

        return res
    
    def tabulate_preds(self):
        # Calculates a prediction for each variant in the train and test set as the average
        # across all predictions made for that variant's observations of dynamics
        
        # Populate the obs attribute
        self.make_observations()

        self.variants = {'train':[],'test':[]}
        self.preds    = {'train':[],'test':[]}
        self.targets  = {'train':[],'test':[]}
        
        # Make predictions for the training variants
        for i,var in enumerate(np.unique(self.train_vars)):
            res = self.score_var(var)
            res = np.concatenate(res)
            self.variants['train'].append(var)
            self.preds['train'].append(np.mean(res))
            self.targets['train'].append(np.log10(self.obs.kcat[np.where(self.obs.variant==var)[0][0]]))
            
            if (i+1)%5 == 0:
                print (f'Completed {i+1}/{np.unique(self.train_vars).shape[0]} train variants...')
                
        # Make predictions for the test variants
        for i,var in enumerate(np.unique(self.test_vars)):
            res = self.score_var(var)
            res = np.concatenate(res)
            self.variants['test'].append(var)
            self.preds['test'].append(np.mean(res))
            self.targets['test'].append(np.log10(self.obs.kcat[np.where(self.obs.variant==var)[0][0]]))
            
            if (i+1)%5 == 0:
                print (f'Completed {i+1}/{np.unique(self.test_vars).shape[0]} test variants...')
        
        res = {'Spearman (test)':None, 'Spearman (train)':None, 'Pearson (test)':None, 'Pearson (train)':None}
        res['Spearman (test)']  = spearmanr(self.preds['test'],  self.targets['test'])#, alternative='greater')
        res['Spearman (train)'] = spearmanr(self.preds['train'], self.targets['train'])#, alternative='greater')
        res['Pearson (test)']   = pearsonr(self.preds['test'],   self.targets['test'])
        res['Pearson (train)']  = pearsonr(self.preds['train'],  self.targets['train'])
        
        return res
    
    def plot_preds(self, figsize=None):
        # Plots predictions vs. labels for both train and test data
        
        if self.variants == None:
            self.tabulate_preds()
            
        low = np.min(self.targets['train']+self.targets['test'])
        high = np.max(self.targets['train']+self.targets['test'])
        
        fig, ax = plt.subplots(1,1,figsize=figsize)
        ax.scatter(self.preds['train'], self.targets['train'], color='k', label='Train')
        ax.scatter(self.preds['test'], self.targets['test'], color='lightgreen', label='Test')
        # ax.scatter(-16.02, -16.02, marker='x', color='b', label='WT')
        ax.plot([low,high], [low,high], color='gray', label=r'$x=y$')
        ax.set_xlabel(r'Predicted $\mathrm{log}(k_{cat})$')
        ax.set_ylabel(r'Target $\mathrm{log}(k_{cat})$ (from TIS)')
        ax.set_title(self.model_file)
        ax.legend()
        
        fig
            
        return fig, ax
        
    @staticmethod
    def get_dir(file):
        # Returns direction under which file is stored
        file_dir = '/'.join(file.split('/')[0:-1]) + '/'
        return file_dir

    @staticmethod
    def get_val_variants(model_file, output_file=None):
        # Returns list of variants that were held out
        # during training of the model saved to model_file
        # INPUT:
        # model_file -- full path to the file to which the 
        #               model was saved
        # output_file -- the text file to which output was 
        #                written by the script that trained
        #                and saved the model

        if output_file == None:
            output_file = ModelTest.get_dir(model_file) + 'transformer_1_output.txt'

        if ModelTest.get_dir(model_file) != ModelTest.get_dir(output_file):
            raise ValueError('model_file and output_file directories do not match.' +\
                             'Are you sure you have the right ones?')

        # get the CV fold
        fold = model_file.split('cvfold')[-1].split('.pt')[0]

        # read the output file
        with open(output_file, 'r') as f:
            data = f.read()

        # grab the variants used for training
        train_vars = data.split(f"epoch 1 | CV fold {fold}")[0].split('Training variants:')[-1]

        # grab the variants used for validation
        val_vars = data.split(f"Best loss achieved, saving model state to best_model_cvfold{fold}.pt")[0]
        val_vars = val_vars.split('Validation variants:')[-1]
        
        train_vars = train_vars.replace("' '",',').replace("'",'').replace('\n ',',').split('[')[-1].split(']')[0].split(',')
        val_vars = val_vars.replace("' '",',').replace("'",'').replace('\n ',',').split('[')[-1].split(']')[0].split(',')

        return np.array(train_vars), np.array(val_vars)