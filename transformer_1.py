"""
AUTHOR: E Karvelis (karvels2@mit.edu)
DATE:   April 25, 2023

PURPOSE: 
Predict TIS-calculated k_cat values for different enzyme mutants as a 
function of their active site dynamics leading up to attempted turnover
events. Observations of the dynamics leading to, and sometimes including,
attempted turnover are referred to as trajectories or pathways. The 
goal of this script is to train a transformer-based model that predicts 
the k_cat for a given mutant based on a sampled set of its trajectories.

METHOD:
This script implements a standard transformer encoder, specialized 
for handling multivariate time series data, upstream of a head that 
predicts k_cat from the pooled encodings across a set of input 
trajectories. 

(set of trajectories) >> transformer encoder >> pooling >> prediction head >> k_cat


EXECUTION:
python transformer_1.py config.txt

where the config.txt file specifies all settings. See below for info on each 
setting. An example file might read:

data_file = 'data/tptrue_gsfalse_o-0dot4_0dot8_s1_2_3_4_5_r1_2_t-110_0_sub500_numNone.470000-111-70memnpy'
meta_file = 'data/tptrue_gsfalse_o-0dot4_0dot8_s1_2_3_4_5_r1_2_t-110_0_sub500_numNone.metadata'
loc = '/data/karvelis03/dl_kcat/'
split_by_variant = True
path_set_size = 10
random_seed = 333
epochs = 100


DEPENDENCIES:
This script sources the object for structuring metadata, which is defined in 
./scripts/prep_data.py. In practice, this script imports everything from prep_data.py.


INPUT:
data_file --        Name of the data file, which stores a memory-mapped numpy array of
			        the form saved by prep_data.py. This array has form 
			        [pathways, timesteps, features]. (str)
meta_file --        Name of the metadata file, which stores the metadata describing 
			        each pathway entry (along axis 0) of the data_file. The meta_file
			        stores a saved, pickled python object generated by prep_data.py when 
			        saving the corresponding data_file (meta_file will have the same name
			        as its data_file, but the suffix of the data_file is replaced with 
			        '.metadata'). This object is an instance of Recurrent_data as defined in
			        scripts/prep_data.py. It contains information associated with each 
			        pathway along axis 0 of the data_file array: the variant, k_cat, 
			        error in k_cat, pathway type (i.e., order), ensemble seed number, 
			        ensemble statistical replicate number, time steps (along axis 1). (str)
loc --              The pathway to the location of the dl_kcat repo. This script has some 
                    dependencies, all of which it can source form the repo's ./scripts
                    and ./input subfolders. (str)
cv_folds --         The number of cross validation folds to use. Default, 5. int
split_by_variant -- Whether to split the cross validation folds by enzyme variants. 
                    That is, if True, then all the pathway data from a given variant
                    will be in only the train or test set (never both) for a given
                    cross validation fold. Each variant is held out in the test set
                    for only one of the folds. If False, then the pathway data from 
                    a given variant can be distributed between both the train and 
                    test sets for every fold. Generally, we set this arument to True,
                    because we are  interested in how the model will generalize to 
                    new variants whose data on which it hasn't been trained. (bool)
path_set_size --    The number of pathways to include per 'observation' of an enzyme
					variant. That is, the model will predict k_cat from a set of 
					path_set_size number of pathways from a given variant. The model
					architecture will be designed so that it can make this prediction
					for any variable number of pathways, but for training purposes, 
					we select the number of pathways so that the training data can 
					be appropriately packed into 'observations,' where each observation 
					is a small set of pathways. Defaults to 10. int
batch_size --       Size of training batches. Each batch will include batch size number 
                    of variant observations, where each observation is comprised of 
                    path_set_size number of pathways. Default, 32. int
random_seed --      Number with which to intialize the random number generator. int
epochs --           Number of training epochs. Default, 100. (int)
d_model -- 			The dimensions of the transformer encoder layers in the, or hidden 
					layer sizes inside transformer encoder. All sublayers in the model 
					will produce outputs with this dimension. (int)
warmup_steps --     The number learning rate warmup steps to use during model training.
                    The learning rate is gradually and linearly increased over the 
                    course of warmup_steps training steps (each training batch and 
                    update of learnable parameters is considered a single step) before 
                    it decays over the course of further training. See function 
                    warmup_decay_lr() or the Attention is All You Need paper (), on 
                    which it is based, for more information. (int)

d_model -- 			The dimensions of the transformer encoder layers in the 
           			transformer encoder. All sublayers in the model will produce
           			outputs with this dimension. (int)
n_head -- 			The number of attention heads (parallel attention layers) in 
          			each transformer encoder layer. Default, 8. (int)
d_tran_ffn -- 		Number of neurons in the linear feedforward layer of the transformer
              		encoder layers. Default, 2048. (int)
dropout_tran_ecoder -- Dropout for the transformer encoder layers. Default, 0.2.
                       (float)
n_tran_layers -- 	Number of stacked transformer encoder layers in the transformer
                 	encoder. Default, 4. (int)
d_mlp_head -- 		Hidden layer size for the (middle layer) of the two layer MLP
              		regression head. (int)
dropout_mlp_head -- Dropout rate applied in between the two layers in the 
                    MLP regression head. (float)
control_model --    Whether to train a negative control model or not. If True, then
					the target (labels) will be scrambled for the training data 
					prior to model training (validation sets' labels are not 
					scrambled). This setting trains a negative control model to 
					get a sense of baseline performance for a naive model that 
					guesses the mean across all variants, for every variant. If
					False, then no data are scrambled. Default, False. (bool)
stoch_labels --		Whether to stochastically sample labels (i.e, log(kcat) values)
					according to the mean and standard error of the mean (SEM) for
					TIS-calculated kcat values, which are specific to each mutant.
					Each variant will have multiple 'observations,' or sets of paths
					from which a prediction is made. When stoch_labels is False, the
					labels for these observations will always be the mean kcat. When 
					stoch, labels is True, the label for each observations will be 
					sampled from a normal disribution with mean = mean kcat and 
					standard deviation = SEM kcat. Default, False. (bool)
selected_variants -- The variants whose data to use. This setting allows one to 
					 specify that only a subset of the variants are to be used. 
					 For example, if you wish to train and test on only WT, you
					 could pass selected_variants = ['WT']. Or if you wanted 
					 to train on only a few of the fastest mutants, you could 
					 pass ['GLn140Met-Thr520Asp', 'Leu501His','Thr520Asp']. 
					 Defaults to '*', in which case all variants available in 
					 the dataset are used. (list of strings, or the character '*')
task 			 -- The type of learning task for which to train and evaluate the 
					model. Must be one of:
					'kcat regression' -- regression task to predict log10(kcat)
					'NR/R binary classification' -- classify paths as either non-reactive or
											 reactive
					Default, 'kcat regression'. (str)
dw_settings 	 -- Passes the parameters to use inside the DenseWeight method for
					controlling the weighting of individual sample's terms in the loss
					function. The DenseWeight method is described here:
					https://link.springer.com/article/10.1007/s10994-021-06023-5, 
					and implemented using their Python package here:
					https://github.com/SteiMi/denseweight, with inspiration taken
					from the original paper's GitHub repo here:
					https://github.com/SteiMi/density-based-weighting-for-imbalanced-regression/tree/main/exp1_and_2.
					dw_settings is a dictionary specifying kwargs for DenseWeight, e.g.
					
					dw_settings = {'alpha':0.9, 'bandwidth':1, 'eps':1e-6'}
					
					'alpha' controls the strength of the weighting. When set 
						to 0, no weighting is applied and all terms are 
						weighed equally. 'alpha' controls the alpha parameter as
						described in the paper. Increasing its value places relatively
						larger weights on the loss terms corresponding to less 
						frequent samples/observations. Therefore, set alpha to
						positive values (0.0 - 2.0 is probably a good range) to 
						more strongly weight less frequent values as a means to give 
						more equal influence across the range of kcat values in 
						our dataset (which is largely biased toward kcat near WT 
						value, otherwise). The higher the value of alpha, the 
						more the weighting emphasizes differences in density of 
						samples/observations. Values around 0.9 are resonable. (float)
					'bandwidth' controls the bandwidth of the kernel density-fitting
					    function used by DenseWeight to calculate the empirical 
					    probability density. Smaller bandwidth = higher resolution.
					    Larger bandwidth = smoother density. A value of 1, the method's
					    default, is reasonable. (float)
					'eps' sets the minimum weight to be applied to a term in the 
					    loss function. The DensWeight default is 1e-6. (float)

					Default, dw_settings = None, in which case no loss weighting 
					is applied. (dict)				


"""

""" ============================================== """
###                     Packages                   ###
""" ============================================== """
import torch
from torch import nn, Tensor
from torch.utils.data import Dataset, DataLoader
from sklearn.model_selection import GroupKFold
import math
import numpy as np
import pandas as pd
import pickle
from denseweight import DenseWeight
import matplotlib.pyplot as plt






""" ============================================== """
###          Helper functions and classes (put in another script one day)          ###
""" ============================================== """
class PathDataset():
	# Stores the memory-mapped numpy array and corresponding
	# Recurrent_data object with associated metadata

	def __init__(self, data_file, meta_file=None, path_set_size=10, selected_variants='*', task='kcat regression'):
		# INPUT:
		# All input are as described at the top of this file

		self.data_file = data_file
		self.path_set_size = path_set_size
		self.selected_variants = selected_variants
		self.task = task

		# set self.uniform parameter:
		# whether each observation of a variant in the self.obs
		# object is comprised of pathways of the same type. If
		# True, then each observation will contain pathways that
		# are all either reactive (R) or non-reactive (NR), but
		# never both. When False (default), observations can 
		# contain a mixture of all types of pathways. (bool)
		if self.task == 'kcat regression':
			self.uniform = False
		elif self.task == 'NR/R binary classification':
			self.uniform = True

		if meta_file != None:
			self.meta_file = meta_file
		else:
			suffix = data_file.split('num')[-1].split('.')[-1]
			self.meta_file = data_file.replace(suffix, 'metadata')


		self.data = np.memmap(self.data_file, dtype='float32', mode='r', shape=self.get_data_shape(self.data_file))
		self.meta = pickle.load(open(self.meta_file, 'rb'))
		self.obs = None

		if self.selected_variants == '*':
			# then use all the variants
			self.selected_variants = np.unique(self.meta.variant)

	def info(self):
		print ("self.data_file -- name of the file the PathDataset is sourcing a memory-mapped numpy array from")
		print ("self.meta_file -- name of the file the PathDataset is sourcing the meta data from (Recurrent_data object)")
		print ("self.data -- the loaded memory-mapped numpy array")
		print ("self.meta -- the loaded Recurrent_data object with metadata")
		print ("self.obs -- instance of Observations object. Stores indexes for each 'observation' of a mutant")


	@staticmethod
	def get_data_shape(data_file):
		suffix = data_file.split('num')[-1].split('.')[-1]
		shape = np.array(suffix.split('memnpy')[0].split('-'), dtype=int)
		shape = tuple(shape)
		return shape

	def make_observations(self):
		# Populates self.obs with an instance of the Observations class
		# 
		# This creates small groups of pathways, where each pathway
		# in a given group is from the same enzyme variant. Such
		# a group of pathways is called an 'observation' of a variant.
		# 
		# Observations are organized in an instance of the Observations 
		# class stored in self.obs.
		# Each observation has one element in the array self.obs.obs,
		# and that element is an array listing the indexes (along axis 0)
		# of self.data for the pathways belonging to that observation.
		# Also included as part of the self.obs instance are the 
		# self.obs.variant, self.obs.kcat, and self.obs.kcat_sem attibutes, 
		# which are arrays that respectively list the variant, kcat, and 
		# kcat SEM associated with each observation in self.obs.obs. Note 
		# that these attributes of self.obs are redundant in that self 
		# already has attributes containing this kind of information. The 
		# copying of variant and kcat-related metrics to self.obs is for 
		# convenience. If this causes issues later on (memory, general 
		# performance), consider doing away with the redundancy.

		self.obs = self.Observations(self)


	class Observations():
		# Populates an array called self.obs, listing the indexes (along axis 0)
		# of PathDataset.data for the pathways belonging to each observation.
		# Also creates self.variant, self.kcat, and self.kcat_sem attibutes, 
		# which are arrays that respectively list the variant, kcat, and 
		# kcat SEM associated with each observation (each row) in self.obs.
		def __init__(self, PathDataset):
			self.obs = []
			self.variant = []
			self.kcat = []
			self.kcat_sem = []
			self.order = []

			for var in np.unique(PathDataset.meta.variant):

				if var in PathDataset.selected_variants:
					
					var_paths = np.where(np.array(PathDataset.meta.variant) == var)[0]

					# get kcat-related metadata
					kcat = PathDataset.meta.kcat[var_paths[0]]
					kcat_sem = PathDataset.meta.kcat_sem[var_paths[0]]

					# group variant's paths into a set of 'observations'
					if not PathDataset.uniform:
						# then each observation may contain a mix of both R and NR pathways
						n_obs = int(np.floor(var_paths.shape[0] / PathDataset.path_set_size))
						var_obs = np.random.choice(var_paths, size=(n_obs,PathDataset.path_set_size), replace=False)
					else:
						# then each observation may only contain either R or NR pathways, not both
						var_paths_nr = var_paths[np.where(np.array(PathDataset.meta.order)[var_paths] != 0.8)]
						n_obs_nr = int(np.floor(var_paths_nr.shape[0] / PathDataset.path_set_size))
						var_obs_nr = np.random.choice(var_paths_nr, size=(n_obs_nr,PathDataset.path_set_size), replace=False)

						var_paths_r = var_paths[np.where(np.array(PathDataset.meta.order)[var_paths] == 0.8)]
						n_obs_r = int(np.floor(var_paths_r.shape[0] / PathDataset.path_set_size))
						var_obs_r = np.random.choice(var_paths_r, size=(n_obs_r,PathDataset.path_set_size), replace=False)

						var_obs = np.vstack((var_obs_nr,var_obs_r))
					
					# append observations to list
					self.obs.append(var_obs)

					# add metadata
					self.variant     += [var]     *var_obs.shape[0]
					self.kcat        += [kcat]    *var_obs.shape[0]
					self.kcat_sem    += [kcat_sem]*var_obs.shape[0]
					self.order.append(np.array(PathDataset.meta.order)[var_obs])

			# convert all data to single numpy arrays
			self.variant = np.array(self.variant)
			self.kcat = np.array(self.kcat)
			self.kcat_sem = np.array(self.kcat_sem)
			self.obs = np.vstack(self.obs)
			self.order = np.vstack(self.order)


class NormalScaler():
	# Similar to sklearn's StandardScaler() in that it scales
	# features to have mean=0 and variance=1 by applying 
	# z = (x-u)/s where z is the udpated feature value, x 
	# the original value, u the mean, and s the standard deviation.
	#
	# Given 3D data of form [pathways, timesteps, features], each 
	# feature's u and s are calculated across all timesteps across
	# all paths. So, there are data.shape[2] number of s and u 
	# in total
	# 
	# call .fit() to fit on training data, then
	# call .transform() to scale both training
	# and testing data as needed
	# 
	# Example:
	# scaler = NormalScaler()
	# scaler.fit(data.data)
	# x = data.data[0:3,:,:]
	# x = scaler.transform(x)

	def __init__(self):
		self.avg = None
		self.std = None

	def fit(self, x):
		self.avg = np.mean(x, axis=(0,1))
		self.std = np.std(x, axis=(0,1))

	def transform(self, x):
		if not isinstance(self.avg, np.ndarray):
			raise ValueError('NormalScaler instance must first be fit to data before transforming data')

		x = (x - self.avg) / self.std

		return x


class MinMaxScaler():
	# Similar to sklearn's MinMaxScaler() in that it scales
	# features to have range from 0 to 1 by applying 
	# x_scaled = (x - min(x))/(max(x) - min(x)) where x_scaled
	# is the udpated feature value, x  the original value
	#
	# Given 3D data of form [pathways, timesteps, features], each 
	# feature's min and max are taken across all timesteps across
	# all paths. So, there are data.shape[2] number of min and max 
	# in total
	# 
	# call .fit() to fit on training data, then
	# call .transform() to scale both training
	# and testing data as needed

	def __init__(self):
		self.min = None
		self.max = None

	def fit(self, x):
		self.min = np.min(np.min(x, axis=1), axis=0)
		self.max = np.max(np.max(x, axis=1), axis=0)

	def transform(self, x):
		if not isinstance(self.min, np.ndarray):
			raise ValueError('MinMaxScaler instance must first be fit to data before transforming data')

		x = (x - self.min) / (self.max - self.min)

		return x 


class DataScaler():
	# A class that can be passed as the transform argument when 
	# making an instance of PathTorchDataset, enabling the 
	# scaling, or normalization, of data as it is called by 
	# the PyTorch Dataloader.
	# INPUT:
	# scaler -- a MinMaxScaler or NormalScaler instance that has
	#           been fit to some data, which you want to apply
	# OUTPUT -- when __call__(sample) executes, this will apply
	#           the .transform() function of scaler to the data
	#           in sample['paths'], i.e. the pathway data

	def __init__(self, scaler, stoch_labels=False):
		self.scaler = scaler
		self.stoch_labels = stoch_labels

	@staticmethod
	def sample_kcat(mean, sem):
		# Samples a value from a normal distribution with mean = mean
		# and standard deviation = sem. Given that kcat must be > 0,
		# in the event that the sampled kcat < 0 (occurs 3-6% of time), 
		# new values are drawn until the sampled kcat is > 0
		kcat = -1
		while kcat <= 0:
			kcat = np.random.normal(loc=mean, scale=sem, size=1)[0]
		kcat = np.float32(np.log10(kcat))
		return kcat 

	def __call__(self, sample):

		paths = self.scaler.transform(sample['paths'])

		if self.stoch_labels:
			# sample kcat value from normal dist with mean = average 
			# kcat and std = SEM of kcat. Note: sample['kcat'] is in 
			# log units, so we take to the power of 10
			kcat = self.sample_kcat(10**sample['kcat'], sample['kcat sem'])
		else:
			kcat = sample['kcat']
		
		try:
			t_sample = {'paths': torch.from_numpy(paths).to(device),
						'kcat': torch.from_numpy(np.array(kcat)).to(device),
						'order': torch.from_numpy(np.array(sample['order'])).to(device)}
		except:
			# executes when PathTorchDataset is imported and executed by external programs
			t_sample = {'paths': torch.from_numpy(paths).to(torch.device('cuda' if torch.cuda.is_available() else 'cpu')),
						'kcat': torch.from_numpy(np.array(kcat)).to(torch.device('cuda' if torch.cuda.is_available() else 'cpu')),
						'order': torch.from_numpy(np.array(sample['order'])).to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))}
			
		return t_sample


class PathTorchDataset(Dataset):
	# Defines a customized Dataset class for use with 
	# PyTorch based on the standard PyTorch Dataset class
	

	def __init__(self, pathdataset, elligible_idxs=None, transform=None, control_model=False):
		# pathdataset -- an instance of the PathDataset object, with the 
		#                .obs attribute populated (PathDataset)
		# elligible_idxs -- the indexes along the attributes of
		#                   pathdataset.obs that are elligible for 
		#                   selection when loading data. This variable
		#                   is meant to pass the indexes of training or 
		#                   testing data. Default, None, in which case
		#                   all indexes are considered elligible. 
		#    				(numpy array, None).
		# transform -- transform to apply to samples (function, optional)
		# control_model -- if True, then the targets (labels), kcat, 
		# 				   will be randomly shuffled. (bool)

		self.pathdataset = pathdataset
		self.transform = transform
		self.control_model = control_model
		if elligible_idxs is None:
			self.elligible_idxs = np.arange(self.pathdataset.obs.obs.shape[0])
		else:
			self.elligible_idxs = elligible_idxs
		
		if self.control_model:
			self.elligible_idxs_shuffled = self.elligible_idxs.copy()
			np.random.shuffle(self.elligible_idxs_shuffled)

	def __len__(self):
		return (self.elligible_idxs.shape[0])

	def __getitem__(self, idx):

		# Convert idx to the index along self.path.dataset.obs
		# entries that is elligible for selection
		selected_idx = self.elligible_idxs[idx]

		# Collect paths' data
		path_idxs = self.pathdataset.obs.obs[selected_idx]
		paths = self.pathdataset.data[path_idxs,:,:]

		# Collect kcat value
		if self.control_model:
			# Update selected index to sample scrambled (random) target labels
			selected_idx = self.elligible_idxs_shuffled[idx]

		kcat = self.pathdataset.obs.kcat[selected_idx]
		kcat_sem = self.pathdataset.obs.kcat_sem[selected_idx]

		# Collect paths' order information
		order = self.pathdataset.obs.order[selected_idx]
		# we'll report order as the average across all the paths'
		# orders in the observation. If pathdataset.uniform, then
		# the average is exactly the order of all the paths in the
		# observation. Otherwise when pathdataset.uniform is False, 
		# the average will range from the lowest NR order to the 
		# R order depending on how many paths in the observation 
		# were R vs. NR
		order = np.mean(order)
		# encode the order parameter, if needed
		if self.pathdataset.task == 'NR/R binary classification': 
			order = 1 if order==0.8 else 0
		order = np.float32(order)

		# take log bc kcat values span several orders of magnitude
		log_kcat = np.float32(np.log10(kcat))
		kcat_sem = np.float32(kcat_sem)

		# try:
			# sample = {'paths': torch.from_numpy(paths).to(device),
			# 			'kcat': log_kcat,
			# 			'kcat sem': kcat_sem,
			# 			'order': order}
		# except:
		# 	# executes when PathTorchDataset is imported and executed by external programs
		# 	sample = {'paths': torch.from_numpy(paths).to(torch.device('cuda' if torch.cuda.is_available() else 'cpu')),
		# 			  'kcat': log_kcat,
		# 			  'kcat sem': kcat_sem,
		# 			  'order': order}

		sample = {'paths': paths,
				  'kcat': log_kcat,
				  'kcat sem': kcat_sem,
				  'order': order}

		if self.transform:
			sample = self.transform(sample)
		else:
			try:
				for i in sample:
					sample[i] = torch.from_numpy(sample[i]).to(device)
			except:
				# executes when PathTorchDataset is imported and executed by external programs
				for i in sample:
					sample[i] = torch.from_numpy(np.array(sample[i])).to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))

		return sample


class PositionalEncoding(nn.Module):
	# Implementation taken from PyTorch documentation at:
	# https://pytorch.org/tutorials/beginner/transformer_tutorial.html
	# INPUT:
	# d_model -- the dimension of the transformer encoder layers, this
	#            is the number of features in the input data after being 
	#            passed through the encoder layer. int
	# dropout -- fraction of neurons subjected to dropout. Default, 0.1.
	#			 float
	# max_len -- the dimensionality of the positional encoding array. 
	#            i.e., the array to be added to input is of shape 
	#            [max_len, 1, d_model], but only the first "input_size"
	#            rows will be added to input data. Here, "input_size"
	#            is the number of time points in the input data

    def __init__(self, d_model: int, dropout: float=0.1, max_len: int=500):
        super().__init__()
        self.dropout = nn.Dropout(p=dropout)

        position = torch.arange(max_len).unsqueeze(1)
        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))
        pe = torch.zeros(max_len, d_model)
        pe[:, 0::2] = torch.sin(position * div_term)
        pe[:, 1::2] = torch.cos(position * div_term)
        self.register_buffer('pe', pe)

    def forward(self, x: Tensor) -> Tensor:
        # INPUT:
        # x -- Tensor of form [seq_len, batch_size, embedding_dim], so 
        #      the data in x need to first be permuted to shift the batch
        #      dimension from axis 0 to axis 1 like so: x = x.permute(1, 0, 2)
        
        ### x = x + self.pe[:x.size(0)]
        
        """
		Can we do the below implementation instead? And require the the 
		second-to-last axis corresponds to the time points?
        """
        # print (f'x.shape: 		{x.shape}')
        # print (f'self.pe.shape: {self.pe.shape}')
        # print (f'self.pe[0:x.size(-2),:].shape: {self.pe[0:x.size(-2),:].shape}\n')
        x = x + self.pe[0:x.size(-2),:]

        return self.dropout(x)


class TransformerModel(nn.Module):
	# Encodes sets of multivariate time series with a transformer, 
	# pools the encodings, then uses the pooled encoding to predict
	# log(kcat) with an MLP prediction head

	def __init__(self, 
				 input_size: int,
				 input_length: int,
				 d_input_enc: int=128,
				 d_model: int=256,
				 max_input_length: int=500,
				 dropout_pos_encoder: float=0.1,
				 n_head: int=4,
				 d_tran_ffn: int=1024,
				 dropout_tran_encoder: float=0.2,
				 n_tran_layers: int=2,
				 d_mlp_head: int=128,
				 dropout_mlp_head: float=0.2,
				 task: str='kcat regression'):
		# INPUT:
		# input_size -- number of features in input. For example, 1 if univariate or 
		# 			    or 70 if using 70 structural features. int
		# input_length -- the length of each time series in time points. int
		# d_input_enc -- hidden layer size for the (middle layer of the) 2 layer input encoder
		# d_model -- the dimensions of the transformer encoder layers in the 
		#            transformer encoder. All sublayers in the model will produce
		#            outputs with this dimension. int
		# max_input_length -- the max length of the input sequence that is being fed to 
		#                 	  the model. This must be at least as large as the number of 
		#                 	  time points (i.e., input_length >= input_data.shape[-2]).
		#                     It is only used in defining the positional encoding.
		#                 	  Default, 500. int
		# dropout_pos_encoder -- dropout for the positional encoding step. Default, 0.1.
		#                        float
		# n_head -- the number of attention heads (parallel attention layers) in 
		#           each transformer encoder layer. Default, 8. int.
		# d_tran_ffn -- number of neurons in the linear feedforward layer of the transformer
		#               encoder layers. Default, 2048. int
		# dropout_tran_ecoder -- dropout for the transformer encoder layers. Default, 0.2.
		#                        float
		# n_tran_layers -- Number of stacked transformer encoder layers in the transformer
		#                  encoder. Default, 4. int
		# d_mlp_head -- hidden layer size for the (middle layer) of the two layer MLP
		#               regression head
		# dropout_mlp_head -- dropout rate applied in between the two layers in the 
		#                     MLP regression head
		# task -- the type of learning task
		# 
		#

		super().__init__()

		self.input_size = input_size
		self.input_length = input_length
		self.model_type = 'PredictiveTransformerEncoder'
		self.task = task

		# Linear layer for encoding raw input
		self.input_encoder = nn.Sequential(nn.Linear(in_features=input_size, out_features=d_input_enc),
										   nn.ReLU(), #nn.Dropout(0.1) ???
							 			   nn.Linear(in_features=d_input_enc, out_features=d_model))

		# Positional encoder
		self.pos_encoder = PositionalEncoding(d_model, dropout_pos_encoder, input_length)

		# Transformer encoder
		encoder_layers = nn.TransformerEncoderLayer(d_model, n_head, 
												   dim_feedforward=d_tran_ffn,
												   dropout=dropout_tran_encoder,
												   batch_first=True)
		self.transformer_encoder = nn.TransformerEncoder(encoder_layers, n_tran_layers)

		# Prediction head (MLP layer)
		self.mlp_head = nn.Sequential(nn.Linear(in_features=d_model, out_features=d_mlp_head),
									  nn.ReLU(),
									  nn.Dropout(dropout_mlp_head),
									  nn.Linear(in_features=d_mlp_head, out_features=1))

		self.sigmoid = nn.Sigmoid() # used when self.task == 'NR/R binary classification'


	def forward(self, src: Tensor, src_mask: Tensor=None) -> Tensor:
		# INPUT
		# src -- the input data of shape [n_paths, timesteps, features] where
		#        n_paths is the number of pathways per observation (usually path_set_size),
		#        timesteps is the number of time steps in the series, and 
		#        features is the number of features (e.g., the 70 structural features).
		#        Tensor
		# src_mask -- the mask for the src sequence to prevent the model using 
		#             specific data point. For now, this should always be set 
		#             to None, because it isn't relevant to our application.
		#  			  Default, None. None or Tensor
		# OUTPUT
		# Returns a predicted value for log10(kcat)

		# Encode input
		# print ('Initial encoding')
		# print (f'src.shape: {src.shape}')
		src = self.input_encoder(src) * math.sqrt(self.input_size)
		# print (f'src.shape: {src.shape}\n\n')

		# Add positional encoding
		# print ('Positional encoding')
		# print (f'src.shape: {src.shape}')
		src = self.pos_encoder(src)
		# print (f'src.shape: {src.shape}\n\n')

		# Pass through transformer encoder
		# print ('Transformer encoding')
		# print (f'src.shape: {src.shape}')
		# start_enc = time.time()
		# enc1 = self.transformer_encoder(src)   ### doesn't work for 4D data
		# print (f'enc runtime: {time.time() - start_enc}')
		# print (f'enc1.shape: {enc1.shape}')

		"""	Rough, brute force way to handle 4D data:
			Just pass each batch one at a time, where each
			batch consists of path_set_size number of pathways.
			The build in transformer layers in PyTorch accept the 
			3D data of a single batch (but not 4D multiple batches).
			It's like you trick it into treating the different pathways
			as different, independent batches at this stage. We want
			independence of pathways at this stage, because their order 
			shouldn't matter, and a downstream pooling operation (or 
			other trainable operations we can think about later) will
			handle the simultaneous consideration of all pathways and 
			how they relate to one another 

			NOTE: the current brute force implementation actually works
			      quite well and is just as fast for processesing something
			      like [32, 10, 111, 512] as processing [320, 111, 512]

		"""
		# start_enc = time.time()
		# enc1 = torch.zeros(src.shape)
		# for i in range(src.shape[0]):
		# 	enc1[i,:,:,:] = self.transformer_encoder(src[i,:,:,:])
		# print (f'enc runtime: {time.time() - start_enc}')
		# print (f'enc1.shape: {enc1.shape}\n\n')


		"""
		Alternative method that involves re-shaping.
		However, I'm not certain the reshaping methods
		preserve the original order and specific structure
		of the data -- need to check that.

		However, in practice the above for-loop option
		seems to run faster, or at least it for sure isn't slower
		"""
		# convert src from 4D to 3D by stacking the first axis
		orig_shape = src.shape
		# print ('Transformer')
		# print (f'src.shape: {src.shape}')
		src = src.view(-1, orig_shape[-2], orig_shape[-1]) # double check that this is equivalent to vstacking
		# print (f'src.shape: {src.shape}')
		enc1 = self.transformer_encoder(src)
		# convert enc1 back to 4D from 3D; this recovers separate batches along first axis
		enc1 = enc1.view(-1, orig_shape[-3], orig_shape[-2], orig_shape[-1]) # double check that this is the inverse of vstacking and recovers the batches
		# print (f'enc1.shape: {enc1.shape}\n\n')


		# Do average pooling for each pathway across its time points
		# print (f'enc1.shape: {enc1.shape}')
		enc1 = torch.mean(enc1, 2)
		# print (f'enc1.shape: {enc1.shape}')


		# Take average across all paths in each observation (experiment with inclusion of other moments and/or max pooling)
		# print ('Averaging over paths')
		# print (f'enc1.shape: {enc1.shape}')
		enc = torch.mean(enc1, 1)
		# print (f'enc.shape: {enc.shape}\n\n')


		# Flatten each observation's averaged time series
		# print ('Flattening avg time series')
		# print (f'enc.shape: {enc.shape}')
		# enc = torch.flatten(enc, start_dim=1)
		# print (f'enc.shape: {enc.shape}\n\n')

		# Prediction head
		# print ('MLP prediction head')
		# print (f'enc.shape: {enc.shape}')
		out = self.mlp_head(enc)
		# print (f'out.shape: {out.shape}')
		# print (out, '\n\n')


		if self.task == 'kcat regression':
			return out
		elif self.task == 'NR/R binary classification':
			return self.sigmoid(out)


class DenseLoss(nn.Module):
    # Implements the DenseLoss loss function using DenseWeight
	# method (and object) as described here:
	# https://link.springer.com/article/10.1007/s10994-021-06023-5
	
	def __init__(self, dw):
		# INPUT:
		# dw -- an instance of DenseWeight that has been fit to data
		#    	by running its .fit() method
		super().__init__()
		self.dw = dw
	
	def forward(self, preds, targets):
		# Calculate relevance (weight) for each sample

		weights = torch.from_numpy( self.dw(targets.cpu().numpy()) ).to(device)

		# Calculate weighted MSE
		err = torch.pow(preds - targets, 2)
		err_weighted = weights * err
		mse = err_weighted.mean()

		return mse


def define_loss(model, dw=None):
	# Defines the loss function based on the model's prediction task, 
	# and whether loss weighting with DenseWeight is activated
	# INPUT:
	# model -- instance of TransformerModel
	# dw -- instance of DenseWeight or None. If None (default),
	#		then DenseWeight and DenseLoss are not applied, and 
	# 		observations' loss terms are weighted equally

	if (model.task == 'kcat regression') and (dw == None):
		loss_fn = nn.MSELoss()
	elif model.task == 'kcat regression':
		loss_fn = DenseLoss(dw)
	elif model.task == 'NR/R binary classification':
		loss_fn = nn.BCELoss()

	return loss_fn


def warmup_decay_lr(step, d_model=256, warmup_steps=4000):
	# Learning rate schedule based on that used in Attention is All You Need:
	# https://arxiv.org/pdf/1706.03762.pdf
	# An adjustment was made to account for the lower-dimensional models
	# used in the default TransformerModel module. Specifically, the original 
	# schedule from Attention is All You Need is multiplied by a factor
	# of 1/sqrt(2) because the dimension of our default TransformerModel 
	# (dmodel) is half that of models used in Attention is All You Need.
	# INPUT:
	# step -- the training step count. Each training batch and update of 
	# 		  learned parameters is considered a single step. int
	# d_model -- the dimensions of the transformer encoder layers in the 
	#            transformer encoder. All sublayers in the model will produce
	#            outputs with this dimension. int
	# warmup_steps -- the number of warmup steps to use. int

	if step == 0:
		return 0

	term1 = step**-0.5
	term2 = step*warmup_steps**-1.5
	term = np.array([term1,term2])

	lr = (2*d_model)**-0.5 * np.min(term, axis=0)

	return lr


def train(model, dataloader) -> None:
	# Training function. Call this once for every epoch to run
	# through the data in dataloader and update the model parameters
	# INPUT:
	# model -- an instance of a PyTorch nn.Module
	# dataloader -- PyTorch DataLoader to stream training data


		model.train()
		total_loss, total_acc = 0.0, 0.0
		start_time = time.time()
		log_interval = 25 # print info every log_interval number of batches

		for batch_idx, batch in enumerate(dataloader):

			# forward pass
			output = model(batch['paths'])

			# print (type(output), output, output.dtype)
			# print (type(batch['kcat'].view(-1,1)), batch['kcat'].view(-1,1), batch['kcat'].view(-1,1).dtype)

			if model.task == 'kcat regression':
				loss = loss_fn(output, batch['kcat'].view(-1,1))
			elif model.task == 'NR/R binary classification':
				loss = loss_fn(output, batch['order'].view(-1,1))
				acc = (output.round() == batch['order'].view(-1,1)).float().mean()
				total_acc += acc

			# backward pass
			optimizer.zero_grad()
			loss.backward()
			# torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5) # uncomment to help prevent gradients from exploding
			# more info: https://pytorch.org/tutorials/beginner/transformer_tutorial.html

			# update weights
			optimizer.step()

			# update loss 
			total_loss += loss.item()


			if ((batch_idx+1) % log_interval == 0) or ((batch_idx+1) == len(dataloader)):
				
				# print progress and info
				time_per_batch = (time.time() - start_time) / log_interval
				current_loss = total_loss / log_interval
				current_acc = total_acc / log_interval # only reported when task is 'NR/R binary classification'
				root_loss = math.sqrt(current_loss)
				curr_lr = scheduler.get_last_lr()[0]

				if model.task == 'kcat regression':
					print (f'epoch {epoch} | CV fold {cv_fold}/{cv_folds} | {batch_idx+1:d}/{len(dataloader):d} batches | '
						   f'lr {curr_lr:0.3e} | seconds/batch {time_per_batch:.3f} | '
						   f'loss {current_loss:.3e} | sqrt(loss) {root_loss:.3e}')
					output_text.write(f'epoch {epoch} | CV fold {cv_fold}/{cv_folds} | {batch_idx+1:d}/{len(dataloader):d} batches | '
						   f'lr {curr_lr:0.3e} | seconds/batch {time_per_batch:.3f} | '
						   f'loss {current_loss:.3e} | sqrt(loss) {root_loss:.3e}\n')

				elif model.task == 'NR/R binary classification':
					print (f'epoch {epoch} | CV fold {cv_fold}/{cv_folds} | {batch_idx+1:d}/{len(dataloader):d} batches | '
						   f'lr {curr_lr:0.3e} | seconds/batch {time_per_batch:.3f} | '
						   f'loss {current_loss:.3e} | sqrt(loss) {root_loss:.3e} | '
						   f'acc {current_acc:.5f}')
					output_text.write(f'epoch {epoch} | CV fold {cv_fold}/{cv_folds} | {batch_idx+1:d}/{len(dataloader):d} batches | '
						   f'lr {curr_lr:0.3e} | seconds/batch {time_per_batch:.3f} | '
						   f'loss {current_loss:.3e} | sqrt(loss) {root_loss:.3e} | '
						   f'acc {current_acc:.5f}\n')

					total_acc = 0.0

				output_text.flush()

				# reset loss and timer for next round of log_interval number of batches
				total_loss = 0.0
				start_time = time.time()


			# update learning rate
			scheduler.step()

def evaluate(model, dataloader) -> float:
	# Model evaluation function. Typically, this is to be
	# executed at the end of every epoch to report the 
	# model performance on held out data
	# INPUT:
	# model -- an instance of a PyTorch nn.Module
	# dataloader -- PyTorch DataLoader to stream validation
	#               or testing data
	# RETURNS:
	# A dictionary with 'total loss' and 'avg loss' items,
	# where the 'avg loss' is the MSE, and the total loss 
	# is the sum of the SE over all observations in dataloader

		model.eval()
		total_loss, total_acc = 0.0, 0.0
		total_obs = 0
		with torch.no_grad():
			for batch_idx, batch in enumerate(dataloader):
				n_obs = batch['paths'].size(0)

				output = model(batch['paths'])

				if model.task == 'kcat regression':
					loss = loss_fn(output, batch['kcat'].view(-1,1))

				elif model.task == 'NR/R binary classification':
					loss = loss_fn(output, batch['order'].view(-1,1))
					acc = (output.round() == batch['order'].view(-1,1)).float().mean()
					total_acc += acc * n_obs

				total_loss += loss.item() * n_obs
				total_obs += n_obs



		avg_loss = total_loss / total_obs # this is equivalent to MSE when doing 'kcat regression' task
		avg_acc  = total_acc / total_obs # this will be 0 when doing 'kcat regression' task

		return {'total loss':total_loss, 'avg loss':avg_loss, 'avg acc':avg_acc}


def plot_dw_alpha(pathdataset, alphas=[0, 0.5, 0.90, 0.95, 1.0], figsize=(16,8), figname=False):
	# Plot weights vs. log10(kcat) for different alpha
	# INPUT
	# pathdataset -- PathDataset object with the .obs attribute
	#				 populated. Or, a PyTorch DataLoader object 
	#				 constructed on a PathDataset object
	# alphas -- the DenseWeight alpha values with which to calculate
	#			weights for each kcat in pathdataset.obs.kcat
	# figsize -- figure size
	# figname -- file to which to save the plot

	if isinstance(pathdataset, PathDataset):
		kcats = np.log10(pathdataset.obs.kcat)

	elif isinstance(pathdataset, DataLoader):
		kcats = []
		for batch_idx, batch in enumerate(pathdataset):
			kcats.append(batch['kcat'].detach().cpu().numpy())
		kcats = np.concatenate(kcats)

	weights = {}
	df = pd.DataFrame(kcats, columns=['kcat'])
	df['bins'] = pd.cut(df['kcat'], bins=5)
	x = np.linspace(np.min(kcats), np.max(kcats), 100)
	for a in alphas:
		dw = DenseWeight(alpha=a, eps=1e-6, bandwidth=1)
		dw.fit(kcats)
		weights[a] = dw(x)
		df[f'weights (a={a})'] = dw(df['kcat'].to_numpy())

	# Plot
	fig, axes = plt.subplots(2, 3, figsize=figsize)
	for i,a in enumerate(weights):
		axes.flatten()[0].plot(x, weights[a], label=fr'$\alpha={a}$')
		
		ax = axes.flatten()[i+1]
		print (df)
		weight_sum = df.groupby(by='bins').apply(lambda x: np.sum(x[f'weights (a={a})'].to_numpy()))
		print (weight_sum)
		weight_sum.plot.bar(x='bins', ax=ax, title=fr'$\alpha={a}$')
		if (i+1) == len(weights):
			for tick in ax.get_xticklabels():
				tick.set_rotation(45)
				tick.set_fontsize=9
		else:
			ax.set_xticklabels(ax.get_xticks(), rotation=45)
		ax.set_ylabel('Sum of weights')
		print ('\n\n')

	axes.flatten()[0].hist(kcats, label=r'$p(log_{10}(k_{cat}))$', density=True)
	axes.flatten()[0].legend(fontsize=9)
	# axes.flatten()[0].set_xlabel(r'$log_{10}(k_{cat})$')
	fig.text(0.5, 0.02, r'$log_{10}(k_{cat})$', ha='center', fontsize=20)
	fig.tight_layout()
	fig.savefig(figname)

	return


""" ============================================== """
###                     Main code                  ###
""" ============================================== """
if __name__ == '__main__':


	""" #=============================================					
	        Load settings and set up environment
	""" #=============================================
	import sys
	import time

	# read in settings to overwrite defaults
	split_by_variant = True
	control_model = False
	random_seed = 333
	path_set_size = 10
	batch_size = 32
	cv_folds = 5
	# lr = 1e-3
	epochs = 50
	output_text = './transformer_1_output.txt'
	d_model = 256
	n_head = 4
	d_tran_ffn = 1024
	dropout_tran_encoder = 0.2
	n_tran_layers = 2
	d_mlp_head = 128
	dropout_mlp_head = 0.2
	warmup_steps = 4000
	stoch_labels = False
	selected_variants = '*'
	task = 'kcat regression'
	dw_settings = None
	with open(sys.argv[1], 'r') as f:
		settings = f.read()
		exec(settings)

	# import dependencies from prep_data.py
	sys.path.append(f'{loc}/scripts/')
	from prep_data import *

	# initialize random number generator
	np.random.seed(random_seed)

	# open a file for writing progress
	output_text = open(output_text, 'w')

	# device configuration
	device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
	print ('DEVICE: ', device)


	""" #=============================================
	                       Load data
	""" #=============================================
	data = PathDataset(data_file, meta_file, path_set_size=path_set_size, 
					   selected_variants=selected_variants, task=task)
	# group pathways into small sets (from same variant)
	data.make_observations()


	""" #=============================================
                        Cross-validation loop
	""" #=============================================
	# define CV splitter
	cv = GroupKFold(n_splits=cv_folds)
	if (len(selected_variants) < cv_folds) and (selected_variants != '*'):
		groups = np.random.choice(cv_folds, size=data.obs.obs.shape[0])
	else:
		groups = data.obs.variant

	for i, (train_idx, test_idx) in enumerate(cv.split(np.arange(data.obs.obs.shape[0]), groups=groups)):

		cv_fold = i+1

		# Define a new model
		model = TransformerModel(input_size=data.data.shape[-1],
								 input_length=data.data.shape[-2],
								 d_model=d_model,
								 n_head=n_head,
								 d_tran_ffn=d_tran_ffn,
								 dropout_tran_encoder=dropout_tran_encoder,
								 n_tran_layers=n_tran_layers,
								 d_mlp_head=d_mlp_head,
								 dropout_mlp_head=dropout_mlp_head,
								 task=task).to(device)

		total_params = sum(p.numel() for p in model.parameters())
		trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
		print (f'Total parameters:     {total_params}')
		print (f'Trainable parameters: {trainable_params}')


		# Fit the scaler to the training data
		scaler = NormalScaler()
		scaler.fit(data.data[np.concatenate(data.obs.obs[train_idx]),:,:])
		train_data_scaler = DataScaler(scaler, stoch_labels=stoch_labels)
		test_data_scaler  = DataScaler(scaler, stoch_labels=False)
		# print ('\n\n\n\n Finished fitting SCALER \n\n\n\n')


		# Fit weighting function to the training data, if weighted loss is activated
		if dw_settings != None:
			dw = DenseWeight(alpha=dw_settings['alpha'],
							 bandwidth=dw_settings['bandwidth'],
							 eps=dw_settings['eps'])
			dw.fit(np.log10(data.obs.kcat[train_idx]))
		else: 
			dw = None


		# Define loss, optimizer, and a learning rate scheduler
		loss_fn = define_loss(model, dw)
		optimizer = torch.optim.Adam(model.parameters(), lr=1) # lr will be scaled and set by scheduler
		scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, warmup_decay_lr)


		# Define datasets and dataloaders for train and test sets
		train_dataset = PathTorchDataset(data, elligible_idxs=train_idx, transform=train_data_scaler, control_model=control_model)
		test_dataset  = PathTorchDataset(data, elligible_idxs=test_idx, transform=test_data_scaler)
		train_variants = np.unique(train_dataset.pathdataset.obs.variant[train_dataset.elligible_idxs])
		test_variants = np.unique(test_dataset.pathdataset.obs.variant[test_dataset.elligible_idxs])

		print ('\n\nTraining variants:')
		print (train_variants, '\n\n')
		output_text.write('\n\nTraining variants:\n')
		output_text.write(str(train_variants))
		output_text.write('\n\n\n')
		output_text.flush()










		# """ TEST BLOCK """

		# initialize data loading, explicitly seed random number generators for reproducibility
		# train_rng, test_rng = torch.Generator(), torch.Generator()
		# train_rng.manual_seed(int(random_seed*1e10/41))
		# test_rng.manual_seed(int(random_seed*1e10/79))
		# train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, generator=train_rng)
		# test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, generator=test_rng)

			
		# # plot_dw_alpha(data, figname='fig.png')
		# plot_dw_alpha(train_loader, figname='fig.png')
		# print ('\n', 1/0)


		# Include this next block in the actual code where appropriate:
		# Fit weighting function if weighted loss is activated
		# if dw_settings != None:
		# 	dw = DenseWeight(alpha=dw_settings['alpha'],
		# 					 bandwidth=dw_settings['bandwidth'],
		# 					 eps=dw_settings['eps'])

		# 	y = np.log10(data.obs.kcat[train_idx])
		# 	print (f'y.shape: {y.shape}')
		# 	print (f'y: {y}')


		# 	dw.fit(y)

		# 	print (f'dw(-10): {dw([0,-10,-15,-16,-18,-26,-30])}')
		# 	print (f'dw(-10): {dw(-11)}')

		# 	print (1/0)




		# for batch_idx, batch in enumerate(train_loader):
			
		# 	print ('BATCH: ', batch_idx)
		# 	print (batch['kcat'])
		# 	print (batch['order'])
		# 	print (batch['paths'].shape)
		# 	print ('\n\n\n\n\n')

		# """ END TEST BLOCK """








		best_val_loss = float('inf')
		best_model_file = f'best_model_cvfold{cv_fold}.pt'
		for epoch in range(1, (epochs+1)):

			start_epoch = time.time()

			# initialize data loading, explicitly seed random number generators for reproducibility
			train_rng, test_rng = torch.Generator(), torch.Generator()
			train_rng.manual_seed(int(random_seed*1e10/41/epoch))
			test_rng.manual_seed(int(random_seed*1e10/79/epoch))
			train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, generator=train_rng)
			test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, generator=test_rng)

			# train and test model
			train(model, train_loader)
			val_results = evaluate(model, test_loader)

			# report results
			epoch_duration = time.time() - start_epoch
			loss, mse, acc = val_results['total loss'], val_results['avg loss'], val_results['avg acc']
			print ('\n\n','-'*80)
			output_text.write('\n\n'+'-'*80+'\n')

			if model.task == 'kcat regression':
				print (f'End of epoch {epoch} | CV fold {cv_fold}/{cv_folds} | '
					   f'time: {epoch_duration:.1f}s | '
	         		   f'valid loss (MSE) {mse:.3f} | RMSE {mse**0.5:.3f}')

				output_text.write(f'End of epoch {epoch} | CV fold {cv_fold}/{cv_folds} | '
					 			  f'time {epoch_duration:.1f}s | '
	         		   			  f'valid loss (MSE) {mse:.3f} | RMSE {mse**0.5:.3f}\n')

			elif model.task == 'NR/R binary classification':
				print (f'End of epoch {epoch} | CV fold {cv_fold}/{cv_folds} | '
					   f' time: {epoch_duration:.1f}s | '
	         		   f'valid loss {mse:.3f} | '
	         		   f'accuracy {acc:.5f}')

				output_text.write(f'End of epoch {epoch} | CV fold {cv_fold}/{cv_folds} | '
								  f'time {epoch_duration:.1f}s | '
	         		   			  f'valid loss {mse:.3f} | '
	         		   			  f'accuracy {acc:.5f}\n')
			
			print ('\nValidation variants:')
			print (test_variants)
			output_text.write('\nValidation variants:\n')
			output_text.write(str(test_variants))
			output_text.write('\n')

			if mse < best_val_loss:
				print (f'\nBest loss achieved, saving model state to {best_model_file}')
				output_text.write(f'\nBest loss achieved, saving model state to {best_model_file}\n')
				best_val_loss = mse
				torch.save(model.state_dict(), best_model_file)
				# to load into model again later:
				# model.load_state_dict(torch.load(best_model_file))

			print ('-'*80, '\n\n')
			output_text.write('-'*80+'\n\n\n')
			output_text.flush()







	output_text.flush()
	output_text.close()
	print ('DONE')



	"""
	Psuedo code:
	for train, test in cv_splits():
		
		# set up a scaler fit to training data
		scaler.fit(training_data)
	
		# Set up dataloaders for train and test sets.
		# These dataloaders can apply the scaler themselves, 
		# or you can do it yourself after they provide data
		train_dataloader = DataLoader(train)
		test_dataloader = DataLoader(test)

		# Set up a fresh new instance of the model
		model = model()

		for epoch in epochs:
			for batch in train_dataloader:
				
				[transform batch with scaler, if needed]

				model.train(batch)
				model.update()

		# evaluate model on test set
		[transform test data with scaler, if needed]
		model.score(test)
		scores.append(score)


	"""






